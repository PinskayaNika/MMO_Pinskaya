{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Пинская_ММО_ЛР5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8mQgVAL3dGcXFEFURmnSx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PinskayaNika/MMO_Pinskaya/blob/main/%D0%9B%D0%A05/%D0%9F%D0%B8%D0%BD%D1%81%D0%BA%D0%B0%D1%8F_%D0%9C%D0%9C%D0%9E_%D0%9B%D0%A05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Лабораторная работа №5\n",
        "## \"**Предобработка и классификация текстовых данных**\"\n",
        "\n",
        "Выполнила: Пинская Н.М.  \n",
        "Группа: ИУ5-21М  \n",
        "\n",
        "  \n",
        "  \n",
        "**Цель лабораторной работы:** изучение методов предобработки и классификации тестовых данных.  \n",
        "\n",
        "  \n",
        "**Задание:**  \n",
        "\n",
        "1.   Для произвольного предложения или текста решите следующие задачи:\n",
        "\n",
        "*   Токенизация.\n",
        "*   Частеречная разметка.\n",
        "*   Лемматизация.\n",
        "*   Выделение (распознавание) именованных сущностей.\n",
        "*   Разбор предложения.\n",
        "\n",
        "2.   Для произвольного набора данных, предназначенного для классификации текстов, решите задачу классификации текста двумя способами:\n",
        "\n",
        "*   Способ 1. На основе CountVectorizer или TfidfVectorizer.\n",
        "*   Способ 2. На основе моделей word2vec или Glove или fastText.\n",
        "*   Сравните качество полученных моделей.\n",
        "\n",
        "Для поиска наборов данных в поисковой системе можно использовать ключевые слова \"datasets for text classification\"."
      ],
      "metadata": {
        "id": "bNYEYE3140Ga"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Rzh6KcoV3wVA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from nltk import tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install natasha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m01J02y1NYfx",
        "outputId": "4e8b0eee-5bdd-43d4-bebe-7eb418259219"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting natasha\n",
            "  Downloading natasha-1.4.0-py3-none-any.whl (34.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.4 MB 87.6 MB/s \n",
            "\u001b[?25hCollecting slovnet>=0.3.0\n",
            "  Downloading slovnet-0.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting razdel>=0.5.0\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting yargy>=0.14.0\n",
            "  Downloading yargy-0.15.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 111 kB/s \n",
            "\u001b[?25hCollecting navec>=0.9.0\n",
            "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
            "Collecting ipymarkup>=0.8.0\n",
            "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
            "Collecting intervaltree>=3\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec>=0.9.0->natasha) (1.21.6)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 55.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: intervaltree\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26119 sha256=9ee62cbe88416d5176f1e0e1a1f4aff152ee78e125bd675951d87a8c90907907\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/85/bd/1001cbb46dcfb71c2001cd7401c6fb250392f22a81ce3722f7\n",
            "Successfully built intervaltree\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, razdel, pymorphy2, navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
            "  Attempting uninstall: intervaltree\n",
            "    Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "Successfully installed dawg-python-0.7.2 intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.4.0 navec-0.10.0 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 razdel-0.5.0 slovnet-0.5.0 yargy-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install razdel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKkgufKvQK-1",
        "outputId": "e6bf8bdb-d360-4d86-e223-19b1650ebc53"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: razdel in /usr/local/lib/python3.7/dist-packages (0.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузим датасет с классификацией записей в сети Твиттер и предполагемой тональностью их содержимого:"
      ],
      "metadata": {
        "id": "I0mV-C-z5t6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Подключение к gogle диску\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YBhjfF4D-WuW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Вывод содержимого папки на диске\n",
        "# import os\n",
        "# data_root = '/content/drive/MyDrive/MMO'\n",
        "# print(os.listdir(data_root))"
      ],
      "metadata": {
        "id": "LiLi-Bzo-XjC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Распаковка архива с датасетом\n",
        "# !unzip /content/drive/MyDrive/MMO/train.zip\n",
        "# # Unpack files from zip-file\n",
        "# # import zipfile\n",
        "# # with zipfile.ZipFile('/content/drive/MyDrive/MMO/ml-latest-small.zip', 'r') as zip_ref:\n",
        "# #     zip_ref.extractall(BASE_DIR)"
      ],
      "metadata": {
        "id": "9gpTYvv--3j-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_class = pd.read_csv('/content/train.csv', sep=\",\")\n",
        "# df_class.head()"
      ],
      "metadata": {
        "id": "GU4q6j1y5wJe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''Эти змееволосые дамочки уже начали раздражать Перси.\n",
        "Они должны были умереть еще три дня назад, когда он сбросил на них ящик с шарами для боулинга в «Баргин-Марте» в Напе. Они должны были отдать концы два дня назад, после того как он переехал их полицейским автомобилем в Мартинесе. И уж точно они должны были сдохнуть, когда он отрезал им головы сегодня утром в Тилден-парке.\n",
        "Перси убивал их и своими глазами видел, как они обращаются в прах, но эти гнусные тетки неизменно возвращались к жизни. Он, похоже, даже не мог надолго от них оторваться.\n",
        "Он взобрался на вершину холма и перевел дух. Сколько времени прошло с тех пор, как он прикончил их в последний раз? Часа два, наверное. Кажется, они теперь не умирают больше чем на два часа…\n",
        "В последние дни Перси почти не спал. Ел он то, что удавалось стянуть по дороге, – жевательную конфету из торгового автомата, черствый бублик или лепешку буррито, хотя прежде он еще так низко не опускался. Одежда его порвалась, местами обгорела и вся была заляпана слюной монстров.\n",
        "Перси до сих пор был жив только потому, что две змееволосые дамочки (они называли себя горгонами) тоже, похоже, оказались не в состоянии его убить. Их когти не оставляли следа на его коже. Если они пытались его укусить – зубы у них ломались. Но Перси уже был на пределе. Скоро он свалится от истощения, а тогда… хоть его и трудно убить, горгоны найдут способ. Он в этом не сомневался.'''\n",
        "\n",
        "text2 = 'Сам факт Посещения является наиболее важным открытием не только за истекшие тринадцать лет, но и за все время существования человечества. Не так уж важно, кто были эти пришельцы. Неважно, откуда они прибыли, зачем прибыли, почему так недолго пробыли и куда девались потом. Важно то, что теперь человечество твердо знает: оно не одиноко во Вселенной. Боюсь, что Институту Внеземных Культур уже никогда больше не повезет сделать более фундаментальное открытие.'\n",
        "\n",
        "test_text = 'Ранним майским утром к гостинице «Дубки» подкатил светло-серый автомобиль. Распахнулась дверца, из машины выскочил человек с трубкой в зубах. Увидев приветливые лица, букеты цветов, он смущённо улыбнулся. Это был профессор Громов. Почётный гость конгресса кибернетиков приехал из Синегорска, сибирского научного городка, и, как всегда, решил остановиться в «Дубках».'"
      ],
      "metadata": {
        "id": "RZwrYgGXNskJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # выделим тестовое сообщение, с которым затем будем выполнять задачи предобработки текста\n",
        "# test_val = 100\n",
        "# texts = df_class['content']\n",
        "# test_text = texts.iloc[test_val]\n",
        "# test_text"
      ],
      "metadata": {
        "id": "OIqy1QZe5xvS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Предобработка текста"
      ],
      "metadata": {
        "id": "TkogmKz-51BB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Токенизация"
      ],
      "metadata": {
        "id": "yeMZx50756Hu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NLTK**  \n",
        "Содержит большое количество токенизаторов. На практике они не всегда стабильно работают для русского языка."
      ],
      "metadata": {
        "id": "i_Bz3tDoptey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "7MxeqYzP59CZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b37f12dc-49df-49cd-e6b7-b2ceff7a4241"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import tokenize\n",
        "dir(tokenize)[:18]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_UQdnpSo8fi",
        "outputId": "9c153b61-b79b-4c61-a38d-798783d60c0e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BlanklineTokenizer',\n",
              " 'LineTokenizer',\n",
              " 'MWETokenizer',\n",
              " 'PunktSentenceTokenizer',\n",
              " 'RegexpTokenizer',\n",
              " 'ReppTokenizer',\n",
              " 'SExprTokenizer',\n",
              " 'SpaceTokenizer',\n",
              " 'StanfordSegmenter',\n",
              " 'TabTokenizer',\n",
              " 'TextTilingTokenizer',\n",
              " 'ToktokTokenizer',\n",
              " 'TreebankWordTokenizer',\n",
              " 'TweetTokenizer',\n",
              " 'WhitespaceTokenizer',\n",
              " 'WordPunctTokenizer',\n",
              " '__builtins__',\n",
              " '__cached__']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Токенизация по предложениям:"
      ],
      "metadata": {
        "id": "5RZ-21M35_dS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_tk_sents = nltk.tokenize.sent_tokenize(test_text)\n",
        "print(len(nltk_tk_sents))\n",
        "nltk_tk_sents"
      ],
      "metadata": {
        "id": "K9yKP2015-ll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94094ff1-31a5-4d64-b0f8-54349d6a8b9c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ранним майским утром к гостинице «Дубки» подкатил светло-серый автомобиль.',\n",
              " 'Распахнулась дверца, из машины выскочил человек с трубкой в зубах.',\n",
              " 'Увидев приветливые лица, букеты цветов, он смущённо улыбнулся.',\n",
              " 'Это был профессор Громов.',\n",
              " 'Почётный гость конгресса кибернетиков приехал из Синегорска, сибирского научного городка, и, как всегда, решил остановиться в «Дубках».']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Токенизация по словам:"
      ],
      "metadata": {
        "id": "OqFfWpCf6FaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_tk_1 = nltk.WordPunctTokenizer()\n",
        "nltk_tk_1.tokenize(test_text)"
      ],
      "metadata": {
        "id": "jUl15WUK6HQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fb174de-1571-4050-de5f-92274dd275b9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ранним',\n",
              " 'майским',\n",
              " 'утром',\n",
              " 'к',\n",
              " 'гостинице',\n",
              " '«',\n",
              " 'Дубки',\n",
              " '»',\n",
              " 'подкатил',\n",
              " 'светло',\n",
              " '-',\n",
              " 'серый',\n",
              " 'автомобиль',\n",
              " '.',\n",
              " 'Распахнулась',\n",
              " 'дверца',\n",
              " ',',\n",
              " 'из',\n",
              " 'машины',\n",
              " 'выскочил',\n",
              " 'человек',\n",
              " 'с',\n",
              " 'трубкой',\n",
              " 'в',\n",
              " 'зубах',\n",
              " '.',\n",
              " 'Увидев',\n",
              " 'приветливые',\n",
              " 'лица',\n",
              " ',',\n",
              " 'букеты',\n",
              " 'цветов',\n",
              " ',',\n",
              " 'он',\n",
              " 'смущённо',\n",
              " 'улыбнулся',\n",
              " '.',\n",
              " 'Это',\n",
              " 'был',\n",
              " 'профессор',\n",
              " 'Громов',\n",
              " '.',\n",
              " 'Почётный',\n",
              " 'гость',\n",
              " 'конгресса',\n",
              " 'кибернетиков',\n",
              " 'приехал',\n",
              " 'из',\n",
              " 'Синегорска',\n",
              " ',',\n",
              " 'сибирского',\n",
              " 'научного',\n",
              " 'городка',\n",
              " ',',\n",
              " 'и',\n",
              " ',',\n",
              " 'как',\n",
              " 'всегда',\n",
              " ',',\n",
              " 'решил',\n",
              " 'остановиться',\n",
              " 'в',\n",
              " '«',\n",
              " 'Дубках',\n",
              " '».']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Natasha**  \n",
        "Для токенизации используется библиотека https://github.com/natasha/razdel"
      ],
      "metadata": {
        "id": "xbJGrVnSpylg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from razdel import tokenize, sentenize"
      ],
      "metadata": {
        "id": "NSUgaUp-QQP_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_tok_text = list(tokenize(text))\n",
        "n_tok_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DshIy77eQcA4",
        "outputId": "f1705375-02dc-40be-f0ff-66a1c661d7d8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Substring(0, 3, 'Эти'),\n",
              " Substring(4, 15, 'змееволосые'),\n",
              " Substring(16, 23, 'дамочки'),\n",
              " Substring(24, 27, 'уже'),\n",
              " Substring(28, 34, 'начали'),\n",
              " Substring(35, 45, 'раздражать'),\n",
              " Substring(46, 51, 'Перси'),\n",
              " Substring(51, 52, '.'),\n",
              " Substring(53, 56, 'Они'),\n",
              " Substring(57, 63, 'должны'),\n",
              " Substring(64, 68, 'были'),\n",
              " Substring(69, 76, 'умереть'),\n",
              " Substring(77, 80, 'еще'),\n",
              " Substring(81, 84, 'три'),\n",
              " Substring(85, 88, 'дня'),\n",
              " Substring(89, 94, 'назад'),\n",
              " Substring(94, 95, ','),\n",
              " Substring(96, 101, 'когда'),\n",
              " Substring(102, 104, 'он'),\n",
              " Substring(105, 112, 'сбросил'),\n",
              " Substring(113, 115, 'на'),\n",
              " Substring(116, 119, 'них'),\n",
              " Substring(120, 124, 'ящик'),\n",
              " Substring(125, 126, 'с'),\n",
              " Substring(127, 133, 'шарами'),\n",
              " Substring(134, 137, 'для'),\n",
              " Substring(138, 146, 'боулинга'),\n",
              " Substring(147, 148, 'в'),\n",
              " Substring(149, 150, '«'),\n",
              " Substring(150, 162, 'Баргин-Марте'),\n",
              " Substring(162, 163, '»'),\n",
              " Substring(164, 165, 'в'),\n",
              " Substring(166, 170, 'Напе'),\n",
              " Substring(170, 171, '.'),\n",
              " Substring(172, 175, 'Они'),\n",
              " Substring(176, 182, 'должны'),\n",
              " Substring(183, 187, 'были'),\n",
              " Substring(188, 194, 'отдать'),\n",
              " Substring(195, 200, 'концы'),\n",
              " Substring(201, 204, 'два'),\n",
              " Substring(205, 208, 'дня'),\n",
              " Substring(209, 214, 'назад'),\n",
              " Substring(214, 215, ','),\n",
              " Substring(216, 221, 'после'),\n",
              " Substring(222, 226, 'того'),\n",
              " Substring(227, 230, 'как'),\n",
              " Substring(231, 233, 'он'),\n",
              " Substring(234, 242, 'переехал'),\n",
              " Substring(243, 245, 'их'),\n",
              " Substring(246, 257, 'полицейским'),\n",
              " Substring(258, 269, 'автомобилем'),\n",
              " Substring(270, 271, 'в'),\n",
              " Substring(272, 281, 'Мартинесе'),\n",
              " Substring(281, 282, '.'),\n",
              " Substring(283, 284, 'И'),\n",
              " Substring(285, 287, 'уж'),\n",
              " Substring(288, 293, 'точно'),\n",
              " Substring(294, 297, 'они'),\n",
              " Substring(298, 304, 'должны'),\n",
              " Substring(305, 309, 'были'),\n",
              " Substring(310, 318, 'сдохнуть'),\n",
              " Substring(318, 319, ','),\n",
              " Substring(320, 325, 'когда'),\n",
              " Substring(326, 328, 'он'),\n",
              " Substring(329, 336, 'отрезал'),\n",
              " Substring(337, 339, 'им'),\n",
              " Substring(340, 346, 'головы'),\n",
              " Substring(347, 354, 'сегодня'),\n",
              " Substring(355, 360, 'утром'),\n",
              " Substring(361, 362, 'в'),\n",
              " Substring(363, 375, 'Тилден-парке'),\n",
              " Substring(375, 376, '.'),\n",
              " Substring(377, 382, 'Перси'),\n",
              " Substring(383, 389, 'убивал'),\n",
              " Substring(390, 392, 'их'),\n",
              " Substring(393, 394, 'и'),\n",
              " Substring(395, 401, 'своими'),\n",
              " Substring(402, 409, 'глазами'),\n",
              " Substring(410, 415, 'видел'),\n",
              " Substring(415, 416, ','),\n",
              " Substring(417, 420, 'как'),\n",
              " Substring(421, 424, 'они'),\n",
              " Substring(425, 435, 'обращаются'),\n",
              " Substring(436, 437, 'в'),\n",
              " Substring(438, 442, 'прах'),\n",
              " Substring(442, 443, ','),\n",
              " Substring(444, 446, 'но'),\n",
              " Substring(447, 450, 'эти'),\n",
              " Substring(451, 458, 'гнусные'),\n",
              " Substring(459, 464, 'тетки'),\n",
              " Substring(465, 474, 'неизменно'),\n",
              " Substring(475, 487, 'возвращались'),\n",
              " Substring(488, 489, 'к'),\n",
              " Substring(490, 495, 'жизни'),\n",
              " Substring(495, 496, '.'),\n",
              " Substring(497, 499, 'Он'),\n",
              " Substring(499, 500, ','),\n",
              " Substring(501, 507, 'похоже'),\n",
              " Substring(507, 508, ','),\n",
              " Substring(509, 513, 'даже'),\n",
              " Substring(514, 516, 'не'),\n",
              " Substring(517, 520, 'мог'),\n",
              " Substring(521, 528, 'надолго'),\n",
              " Substring(529, 531, 'от'),\n",
              " Substring(532, 535, 'них'),\n",
              " Substring(536, 546, 'оторваться'),\n",
              " Substring(546, 547, '.'),\n",
              " Substring(548, 550, 'Он'),\n",
              " Substring(551, 560, 'взобрался'),\n",
              " Substring(561, 563, 'на'),\n",
              " Substring(564, 571, 'вершину'),\n",
              " Substring(572, 577, 'холма'),\n",
              " Substring(578, 579, 'и'),\n",
              " Substring(580, 587, 'перевел'),\n",
              " Substring(588, 591, 'дух'),\n",
              " Substring(591, 592, '.'),\n",
              " Substring(593, 600, 'Сколько'),\n",
              " Substring(601, 608, 'времени'),\n",
              " Substring(609, 615, 'прошло'),\n",
              " Substring(616, 617, 'с'),\n",
              " Substring(618, 621, 'тех'),\n",
              " Substring(622, 625, 'пор'),\n",
              " Substring(625, 626, ','),\n",
              " Substring(627, 630, 'как'),\n",
              " Substring(631, 633, 'он'),\n",
              " Substring(634, 643, 'прикончил'),\n",
              " Substring(644, 646, 'их'),\n",
              " Substring(647, 648, 'в'),\n",
              " Substring(649, 658, 'последний'),\n",
              " Substring(659, 662, 'раз'),\n",
              " Substring(662, 663, '?'),\n",
              " Substring(664, 668, 'Часа'),\n",
              " Substring(669, 672, 'два'),\n",
              " Substring(672, 673, ','),\n",
              " Substring(674, 682, 'наверное'),\n",
              " Substring(682, 683, '.'),\n",
              " Substring(684, 691, 'Кажется'),\n",
              " Substring(691, 692, ','),\n",
              " Substring(693, 696, 'они'),\n",
              " Substring(697, 703, 'теперь'),\n",
              " Substring(704, 706, 'не'),\n",
              " Substring(707, 714, 'умирают'),\n",
              " Substring(715, 721, 'больше'),\n",
              " Substring(722, 725, 'чем'),\n",
              " Substring(726, 728, 'на'),\n",
              " Substring(729, 732, 'два'),\n",
              " Substring(733, 737, 'часа'),\n",
              " Substring(737, 738, '…'),\n",
              " Substring(739, 740, 'В'),\n",
              " Substring(741, 750, 'последние'),\n",
              " Substring(751, 754, 'дни'),\n",
              " Substring(755, 760, 'Перси'),\n",
              " Substring(761, 766, 'почти'),\n",
              " Substring(767, 769, 'не'),\n",
              " Substring(770, 774, 'спал'),\n",
              " Substring(774, 775, '.'),\n",
              " Substring(776, 778, 'Ел'),\n",
              " Substring(779, 781, 'он'),\n",
              " Substring(782, 784, 'то'),\n",
              " Substring(784, 785, ','),\n",
              " Substring(786, 789, 'что'),\n",
              " Substring(790, 799, 'удавалось'),\n",
              " Substring(800, 807, 'стянуть'),\n",
              " Substring(808, 810, 'по'),\n",
              " Substring(811, 817, 'дороге'),\n",
              " Substring(817, 818, ','),\n",
              " Substring(819, 820, '–'),\n",
              " Substring(821, 832, 'жевательную'),\n",
              " Substring(833, 840, 'конфету'),\n",
              " Substring(841, 843, 'из'),\n",
              " Substring(844, 853, 'торгового'),\n",
              " Substring(854, 862, 'автомата'),\n",
              " Substring(862, 863, ','),\n",
              " Substring(864, 872, 'черствый'),\n",
              " Substring(873, 879, 'бублик'),\n",
              " Substring(880, 883, 'или'),\n",
              " Substring(884, 891, 'лепешку'),\n",
              " Substring(892, 899, 'буррито'),\n",
              " Substring(899, 900, ','),\n",
              " Substring(901, 905, 'хотя'),\n",
              " Substring(906, 912, 'прежде'),\n",
              " Substring(913, 915, 'он'),\n",
              " Substring(916, 919, 'еще'),\n",
              " Substring(920, 923, 'так'),\n",
              " Substring(924, 929, 'низко'),\n",
              " Substring(930, 932, 'не'),\n",
              " Substring(933, 942, 'опускался'),\n",
              " Substring(942, 943, '.'),\n",
              " Substring(944, 950, 'Одежда'),\n",
              " Substring(951, 954, 'его'),\n",
              " Substring(955, 964, 'порвалась'),\n",
              " Substring(964, 965, ','),\n",
              " Substring(966, 973, 'местами'),\n",
              " Substring(974, 982, 'обгорела'),\n",
              " Substring(983, 984, 'и'),\n",
              " Substring(985, 988, 'вся'),\n",
              " Substring(989, 993, 'была'),\n",
              " Substring(994, 1002, 'заляпана'),\n",
              " Substring(1003, 1009, 'слюной'),\n",
              " Substring(1010, 1018, 'монстров'),\n",
              " Substring(1018, 1019, '.'),\n",
              " Substring(1020, 1025, 'Перси'),\n",
              " Substring(1026, 1028, 'до'),\n",
              " Substring(1029, 1032, 'сих'),\n",
              " Substring(1033, 1036, 'пор'),\n",
              " Substring(1037, 1040, 'был'),\n",
              " Substring(1041, 1044, 'жив'),\n",
              " Substring(1045, 1051, 'только'),\n",
              " Substring(1052, 1058, 'потому'),\n",
              " Substring(1058, 1059, ','),\n",
              " Substring(1060, 1063, 'что'),\n",
              " Substring(1064, 1067, 'две'),\n",
              " Substring(1068, 1079, 'змееволосые'),\n",
              " Substring(1080, 1087, 'дамочки'),\n",
              " Substring(1088, 1089, '('),\n",
              " Substring(1089, 1092, 'они'),\n",
              " Substring(1093, 1101, 'называли'),\n",
              " Substring(1102, 1106, 'себя'),\n",
              " Substring(1107, 1116, 'горгонами'),\n",
              " Substring(1116, 1117, ')'),\n",
              " Substring(1118, 1122, 'тоже'),\n",
              " Substring(1122, 1123, ','),\n",
              " Substring(1124, 1130, 'похоже'),\n",
              " Substring(1130, 1131, ','),\n",
              " Substring(1132, 1141, 'оказались'),\n",
              " Substring(1142, 1144, 'не'),\n",
              " Substring(1145, 1146, 'в'),\n",
              " Substring(1147, 1156, 'состоянии'),\n",
              " Substring(1157, 1160, 'его'),\n",
              " Substring(1161, 1166, 'убить'),\n",
              " Substring(1166, 1167, '.'),\n",
              " Substring(1168, 1170, 'Их'),\n",
              " Substring(1171, 1176, 'когти'),\n",
              " Substring(1177, 1179, 'не'),\n",
              " Substring(1180, 1189, 'оставляли'),\n",
              " Substring(1190, 1195, 'следа'),\n",
              " Substring(1196, 1198, 'на'),\n",
              " Substring(1199, 1202, 'его'),\n",
              " Substring(1203, 1207, 'коже'),\n",
              " Substring(1207, 1208, '.'),\n",
              " Substring(1209, 1213, 'Если'),\n",
              " Substring(1214, 1217, 'они'),\n",
              " Substring(1218, 1226, 'пытались'),\n",
              " Substring(1227, 1230, 'его'),\n",
              " Substring(1231, 1238, 'укусить'),\n",
              " Substring(1239, 1240, '–'),\n",
              " Substring(1241, 1245, 'зубы'),\n",
              " Substring(1246, 1247, 'у'),\n",
              " Substring(1248, 1251, 'них'),\n",
              " Substring(1252, 1260, 'ломались'),\n",
              " Substring(1260, 1261, '.'),\n",
              " Substring(1262, 1264, 'Но'),\n",
              " Substring(1265, 1270, 'Перси'),\n",
              " Substring(1271, 1274, 'уже'),\n",
              " Substring(1275, 1278, 'был'),\n",
              " Substring(1279, 1281, 'на'),\n",
              " Substring(1282, 1289, 'пределе'),\n",
              " Substring(1289, 1290, '.'),\n",
              " Substring(1291, 1296, 'Скоро'),\n",
              " Substring(1297, 1299, 'он'),\n",
              " Substring(1300, 1308, 'свалится'),\n",
              " Substring(1309, 1311, 'от'),\n",
              " Substring(1312, 1321, 'истощения'),\n",
              " Substring(1321, 1322, ','),\n",
              " Substring(1323, 1324, 'а'),\n",
              " Substring(1325, 1330, 'тогда'),\n",
              " Substring(1330, 1331, '…'),\n",
              " Substring(1332, 1336, 'хоть'),\n",
              " Substring(1337, 1340, 'его'),\n",
              " Substring(1341, 1342, 'и'),\n",
              " Substring(1343, 1349, 'трудно'),\n",
              " Substring(1350, 1355, 'убить'),\n",
              " Substring(1355, 1356, ','),\n",
              " Substring(1357, 1364, 'горгоны'),\n",
              " Substring(1365, 1371, 'найдут'),\n",
              " Substring(1372, 1378, 'способ'),\n",
              " Substring(1378, 1379, '.'),\n",
              " Substring(1380, 1382, 'Он'),\n",
              " Substring(1383, 1384, 'в'),\n",
              " Substring(1385, 1389, 'этом'),\n",
              " Substring(1390, 1392, 'не'),\n",
              " Substring(1393, 1403, 'сомневался'),\n",
              " Substring(1403, 1404, '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[_.text for _ in n_tok_text]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjNii1IlQcid",
        "outputId": "675b4966-e156-4734-d4a7-c5ee9f4e9a77"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Эти',\n",
              " 'змееволосые',\n",
              " 'дамочки',\n",
              " 'уже',\n",
              " 'начали',\n",
              " 'раздражать',\n",
              " 'Перси',\n",
              " '.',\n",
              " 'Они',\n",
              " 'должны',\n",
              " 'были',\n",
              " 'умереть',\n",
              " 'еще',\n",
              " 'три',\n",
              " 'дня',\n",
              " 'назад',\n",
              " ',',\n",
              " 'когда',\n",
              " 'он',\n",
              " 'сбросил',\n",
              " 'на',\n",
              " 'них',\n",
              " 'ящик',\n",
              " 'с',\n",
              " 'шарами',\n",
              " 'для',\n",
              " 'боулинга',\n",
              " 'в',\n",
              " '«',\n",
              " 'Баргин-Марте',\n",
              " '»',\n",
              " 'в',\n",
              " 'Напе',\n",
              " '.',\n",
              " 'Они',\n",
              " 'должны',\n",
              " 'были',\n",
              " 'отдать',\n",
              " 'концы',\n",
              " 'два',\n",
              " 'дня',\n",
              " 'назад',\n",
              " ',',\n",
              " 'после',\n",
              " 'того',\n",
              " 'как',\n",
              " 'он',\n",
              " 'переехал',\n",
              " 'их',\n",
              " 'полицейским',\n",
              " 'автомобилем',\n",
              " 'в',\n",
              " 'Мартинесе',\n",
              " '.',\n",
              " 'И',\n",
              " 'уж',\n",
              " 'точно',\n",
              " 'они',\n",
              " 'должны',\n",
              " 'были',\n",
              " 'сдохнуть',\n",
              " ',',\n",
              " 'когда',\n",
              " 'он',\n",
              " 'отрезал',\n",
              " 'им',\n",
              " 'головы',\n",
              " 'сегодня',\n",
              " 'утром',\n",
              " 'в',\n",
              " 'Тилден-парке',\n",
              " '.',\n",
              " 'Перси',\n",
              " 'убивал',\n",
              " 'их',\n",
              " 'и',\n",
              " 'своими',\n",
              " 'глазами',\n",
              " 'видел',\n",
              " ',',\n",
              " 'как',\n",
              " 'они',\n",
              " 'обращаются',\n",
              " 'в',\n",
              " 'прах',\n",
              " ',',\n",
              " 'но',\n",
              " 'эти',\n",
              " 'гнусные',\n",
              " 'тетки',\n",
              " 'неизменно',\n",
              " 'возвращались',\n",
              " 'к',\n",
              " 'жизни',\n",
              " '.',\n",
              " 'Он',\n",
              " ',',\n",
              " 'похоже',\n",
              " ',',\n",
              " 'даже',\n",
              " 'не',\n",
              " 'мог',\n",
              " 'надолго',\n",
              " 'от',\n",
              " 'них',\n",
              " 'оторваться',\n",
              " '.',\n",
              " 'Он',\n",
              " 'взобрался',\n",
              " 'на',\n",
              " 'вершину',\n",
              " 'холма',\n",
              " 'и',\n",
              " 'перевел',\n",
              " 'дух',\n",
              " '.',\n",
              " 'Сколько',\n",
              " 'времени',\n",
              " 'прошло',\n",
              " 'с',\n",
              " 'тех',\n",
              " 'пор',\n",
              " ',',\n",
              " 'как',\n",
              " 'он',\n",
              " 'прикончил',\n",
              " 'их',\n",
              " 'в',\n",
              " 'последний',\n",
              " 'раз',\n",
              " '?',\n",
              " 'Часа',\n",
              " 'два',\n",
              " ',',\n",
              " 'наверное',\n",
              " '.',\n",
              " 'Кажется',\n",
              " ',',\n",
              " 'они',\n",
              " 'теперь',\n",
              " 'не',\n",
              " 'умирают',\n",
              " 'больше',\n",
              " 'чем',\n",
              " 'на',\n",
              " 'два',\n",
              " 'часа',\n",
              " '…',\n",
              " 'В',\n",
              " 'последние',\n",
              " 'дни',\n",
              " 'Перси',\n",
              " 'почти',\n",
              " 'не',\n",
              " 'спал',\n",
              " '.',\n",
              " 'Ел',\n",
              " 'он',\n",
              " 'то',\n",
              " ',',\n",
              " 'что',\n",
              " 'удавалось',\n",
              " 'стянуть',\n",
              " 'по',\n",
              " 'дороге',\n",
              " ',',\n",
              " '–',\n",
              " 'жевательную',\n",
              " 'конфету',\n",
              " 'из',\n",
              " 'торгового',\n",
              " 'автомата',\n",
              " ',',\n",
              " 'черствый',\n",
              " 'бублик',\n",
              " 'или',\n",
              " 'лепешку',\n",
              " 'буррито',\n",
              " ',',\n",
              " 'хотя',\n",
              " 'прежде',\n",
              " 'он',\n",
              " 'еще',\n",
              " 'так',\n",
              " 'низко',\n",
              " 'не',\n",
              " 'опускался',\n",
              " '.',\n",
              " 'Одежда',\n",
              " 'его',\n",
              " 'порвалась',\n",
              " ',',\n",
              " 'местами',\n",
              " 'обгорела',\n",
              " 'и',\n",
              " 'вся',\n",
              " 'была',\n",
              " 'заляпана',\n",
              " 'слюной',\n",
              " 'монстров',\n",
              " '.',\n",
              " 'Перси',\n",
              " 'до',\n",
              " 'сих',\n",
              " 'пор',\n",
              " 'был',\n",
              " 'жив',\n",
              " 'только',\n",
              " 'потому',\n",
              " ',',\n",
              " 'что',\n",
              " 'две',\n",
              " 'змееволосые',\n",
              " 'дамочки',\n",
              " '(',\n",
              " 'они',\n",
              " 'называли',\n",
              " 'себя',\n",
              " 'горгонами',\n",
              " ')',\n",
              " 'тоже',\n",
              " ',',\n",
              " 'похоже',\n",
              " ',',\n",
              " 'оказались',\n",
              " 'не',\n",
              " 'в',\n",
              " 'состоянии',\n",
              " 'его',\n",
              " 'убить',\n",
              " '.',\n",
              " 'Их',\n",
              " 'когти',\n",
              " 'не',\n",
              " 'оставляли',\n",
              " 'следа',\n",
              " 'на',\n",
              " 'его',\n",
              " 'коже',\n",
              " '.',\n",
              " 'Если',\n",
              " 'они',\n",
              " 'пытались',\n",
              " 'его',\n",
              " 'укусить',\n",
              " '–',\n",
              " 'зубы',\n",
              " 'у',\n",
              " 'них',\n",
              " 'ломались',\n",
              " '.',\n",
              " 'Но',\n",
              " 'Перси',\n",
              " 'уже',\n",
              " 'был',\n",
              " 'на',\n",
              " 'пределе',\n",
              " '.',\n",
              " 'Скоро',\n",
              " 'он',\n",
              " 'свалится',\n",
              " 'от',\n",
              " 'истощения',\n",
              " ',',\n",
              " 'а',\n",
              " 'тогда',\n",
              " '…',\n",
              " 'хоть',\n",
              " 'его',\n",
              " 'и',\n",
              " 'трудно',\n",
              " 'убить',\n",
              " ',',\n",
              " 'горгоны',\n",
              " 'найдут',\n",
              " 'способ',\n",
              " '.',\n",
              " 'Он',\n",
              " 'в',\n",
              " 'этом',\n",
              " 'не',\n",
              " 'сомневался',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_sen_text = list(sentenize(text))\n",
        "n_sen_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixSJ1ERPQqt2",
        "outputId": "1e286160-b2cb-450b-cd46-64eb743aa264"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Substring(0, 52, 'Эти змееволосые дамочки уже начали раздражать Перси.'),\n",
              " Substring(53,\n",
              "           171,\n",
              "           'Они должны были умереть еще три дня назад, когда он сбросил на них ящик с шарами для боулинга в «Баргин-Марте» в Напе.'),\n",
              " Substring(172,\n",
              "           282,\n",
              "           'Они должны были отдать концы два дня назад, после того как он переехал их полицейским автомобилем в Мартинесе.'),\n",
              " Substring(283,\n",
              "           376,\n",
              "           'И уж точно они должны были сдохнуть, когда он отрезал им головы сегодня утром в Тилден-парке.'),\n",
              " Substring(377,\n",
              "           496,\n",
              "           'Перси убивал их и своими глазами видел, как они обращаются в прах, но эти гнусные тетки неизменно возвращались к жизни.'),\n",
              " Substring(497, 547, 'Он, похоже, даже не мог надолго от них оторваться.'),\n",
              " Substring(548, 592, 'Он взобрался на вершину холма и перевел дух.'),\n",
              " Substring(593,\n",
              "           663,\n",
              "           'Сколько времени прошло с тех пор, как он прикончил их в последний раз?'),\n",
              " Substring(664, 683, 'Часа два, наверное.'),\n",
              " Substring(684, 738, 'Кажется, они теперь не умирают больше чем на два часа…'),\n",
              " Substring(739, 775, 'В последние дни Перси почти не спал.'),\n",
              " Substring(776,\n",
              "           943,\n",
              "           'Ел он то, что удавалось стянуть по дороге, – жевательную конфету из торгового автомата, черствый бублик или лепешку буррито, хотя прежде он еще так низко не опускался.'),\n",
              " Substring(944,\n",
              "           1019,\n",
              "           'Одежда его порвалась, местами обгорела и вся была заляпана слюной монстров.'),\n",
              " Substring(1020,\n",
              "           1167,\n",
              "           'Перси до сих пор был жив только потому, что две змееволосые дамочки (они называли себя горгонами) тоже, похоже, оказались не в состоянии его убить.'),\n",
              " Substring(1168, 1208, 'Их когти не оставляли следа на его коже.'),\n",
              " Substring(1209, 1261, 'Если они пытались его укусить – зубы у них ломались.'),\n",
              " Substring(1262, 1290, 'Но Перси уже был на пределе.'),\n",
              " Substring(1291,\n",
              "           1379,\n",
              "           'Скоро он свалится от истощения, а тогда… хоть его и трудно убить, горгоны найдут способ.'),\n",
              " Substring(1380, 1404, 'Он в этом не сомневался.')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[_.text for _ in n_sen_text], len([_.text for _ in n_sen_text])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svQYbaCWQriq",
        "outputId": "a8ae14a6-1bc9-4ac8-831a-ee51eaec4fdf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Эти змееволосые дамочки уже начали раздражать Перси.',\n",
              "  'Они должны были умереть еще три дня назад, когда он сбросил на них ящик с шарами для боулинга в «Баргин-Марте» в Напе.',\n",
              "  'Они должны были отдать концы два дня назад, после того как он переехал их полицейским автомобилем в Мартинесе.',\n",
              "  'И уж точно они должны были сдохнуть, когда он отрезал им головы сегодня утром в Тилден-парке.',\n",
              "  'Перси убивал их и своими глазами видел, как они обращаются в прах, но эти гнусные тетки неизменно возвращались к жизни.',\n",
              "  'Он, похоже, даже не мог надолго от них оторваться.',\n",
              "  'Он взобрался на вершину холма и перевел дух.',\n",
              "  'Сколько времени прошло с тех пор, как он прикончил их в последний раз?',\n",
              "  'Часа два, наверное.',\n",
              "  'Кажется, они теперь не умирают больше чем на два часа…',\n",
              "  'В последние дни Перси почти не спал.',\n",
              "  'Ел он то, что удавалось стянуть по дороге, – жевательную конфету из торгового автомата, черствый бублик или лепешку буррито, хотя прежде он еще так низко не опускался.',\n",
              "  'Одежда его порвалась, местами обгорела и вся была заляпана слюной монстров.',\n",
              "  'Перси до сих пор был жив только потому, что две змееволосые дамочки (они называли себя горгонами) тоже, похоже, оказались не в состоянии его убить.',\n",
              "  'Их когти не оставляли следа на его коже.',\n",
              "  'Если они пытались его укусить – зубы у них ломались.',\n",
              "  'Но Перси уже был на пределе.',\n",
              "  'Скоро он свалится от истощения, а тогда… хоть его и трудно убить, горгоны найдут способ.',\n",
              "  'Он в этом не сомневался.'],\n",
              " 19)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Этот вариант токенизации нужен для последующей обработки\n",
        "def n_sentenize(text):\n",
        "    n_sen_chunk = []\n",
        "    for sent in sentenize(text):\n",
        "        tokens = [_.text for _ in tokenize(sent.text)]\n",
        "        n_sen_chunk.append(tokens)\n",
        "    return n_sen_chunk"
      ],
      "metadata": {
        "id": "78LQGe5NQy5S"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_sen_chunk = n_sentenize(text)\n",
        "n_sen_chunk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSFbNwwbQz1v",
        "outputId": "8c86dc33-12e5-4f83-d7df-658c72d13686"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Эти',\n",
              "  'змееволосые',\n",
              "  'дамочки',\n",
              "  'уже',\n",
              "  'начали',\n",
              "  'раздражать',\n",
              "  'Перси',\n",
              "  '.'],\n",
              " ['Они',\n",
              "  'должны',\n",
              "  'были',\n",
              "  'умереть',\n",
              "  'еще',\n",
              "  'три',\n",
              "  'дня',\n",
              "  'назад',\n",
              "  ',',\n",
              "  'когда',\n",
              "  'он',\n",
              "  'сбросил',\n",
              "  'на',\n",
              "  'них',\n",
              "  'ящик',\n",
              "  'с',\n",
              "  'шарами',\n",
              "  'для',\n",
              "  'боулинга',\n",
              "  'в',\n",
              "  '«',\n",
              "  'Баргин-Марте',\n",
              "  '»',\n",
              "  'в',\n",
              "  'Напе',\n",
              "  '.'],\n",
              " ['Они',\n",
              "  'должны',\n",
              "  'были',\n",
              "  'отдать',\n",
              "  'концы',\n",
              "  'два',\n",
              "  'дня',\n",
              "  'назад',\n",
              "  ',',\n",
              "  'после',\n",
              "  'того',\n",
              "  'как',\n",
              "  'он',\n",
              "  'переехал',\n",
              "  'их',\n",
              "  'полицейским',\n",
              "  'автомобилем',\n",
              "  'в',\n",
              "  'Мартинесе',\n",
              "  '.'],\n",
              " ['И',\n",
              "  'уж',\n",
              "  'точно',\n",
              "  'они',\n",
              "  'должны',\n",
              "  'были',\n",
              "  'сдохнуть',\n",
              "  ',',\n",
              "  'когда',\n",
              "  'он',\n",
              "  'отрезал',\n",
              "  'им',\n",
              "  'головы',\n",
              "  'сегодня',\n",
              "  'утром',\n",
              "  'в',\n",
              "  'Тилден-парке',\n",
              "  '.'],\n",
              " ['Перси',\n",
              "  'убивал',\n",
              "  'их',\n",
              "  'и',\n",
              "  'своими',\n",
              "  'глазами',\n",
              "  'видел',\n",
              "  ',',\n",
              "  'как',\n",
              "  'они',\n",
              "  'обращаются',\n",
              "  'в',\n",
              "  'прах',\n",
              "  ',',\n",
              "  'но',\n",
              "  'эти',\n",
              "  'гнусные',\n",
              "  'тетки',\n",
              "  'неизменно',\n",
              "  'возвращались',\n",
              "  'к',\n",
              "  'жизни',\n",
              "  '.'],\n",
              " ['Он',\n",
              "  ',',\n",
              "  'похоже',\n",
              "  ',',\n",
              "  'даже',\n",
              "  'не',\n",
              "  'мог',\n",
              "  'надолго',\n",
              "  'от',\n",
              "  'них',\n",
              "  'оторваться',\n",
              "  '.'],\n",
              " ['Он', 'взобрался', 'на', 'вершину', 'холма', 'и', 'перевел', 'дух', '.'],\n",
              " ['Сколько',\n",
              "  'времени',\n",
              "  'прошло',\n",
              "  'с',\n",
              "  'тех',\n",
              "  'пор',\n",
              "  ',',\n",
              "  'как',\n",
              "  'он',\n",
              "  'прикончил',\n",
              "  'их',\n",
              "  'в',\n",
              "  'последний',\n",
              "  'раз',\n",
              "  '?'],\n",
              " ['Часа', 'два', ',', 'наверное', '.'],\n",
              " ['Кажется',\n",
              "  ',',\n",
              "  'они',\n",
              "  'теперь',\n",
              "  'не',\n",
              "  'умирают',\n",
              "  'больше',\n",
              "  'чем',\n",
              "  'на',\n",
              "  'два',\n",
              "  'часа',\n",
              "  '…'],\n",
              " ['В', 'последние', 'дни', 'Перси', 'почти', 'не', 'спал', '.'],\n",
              " ['Ел',\n",
              "  'он',\n",
              "  'то',\n",
              "  ',',\n",
              "  'что',\n",
              "  'удавалось',\n",
              "  'стянуть',\n",
              "  'по',\n",
              "  'дороге',\n",
              "  ',',\n",
              "  '–',\n",
              "  'жевательную',\n",
              "  'конфету',\n",
              "  'из',\n",
              "  'торгового',\n",
              "  'автомата',\n",
              "  ',',\n",
              "  'черствый',\n",
              "  'бублик',\n",
              "  'или',\n",
              "  'лепешку',\n",
              "  'буррито',\n",
              "  ',',\n",
              "  'хотя',\n",
              "  'прежде',\n",
              "  'он',\n",
              "  'еще',\n",
              "  'так',\n",
              "  'низко',\n",
              "  'не',\n",
              "  'опускался',\n",
              "  '.'],\n",
              " ['Одежда',\n",
              "  'его',\n",
              "  'порвалась',\n",
              "  ',',\n",
              "  'местами',\n",
              "  'обгорела',\n",
              "  'и',\n",
              "  'вся',\n",
              "  'была',\n",
              "  'заляпана',\n",
              "  'слюной',\n",
              "  'монстров',\n",
              "  '.'],\n",
              " ['Перси',\n",
              "  'до',\n",
              "  'сих',\n",
              "  'пор',\n",
              "  'был',\n",
              "  'жив',\n",
              "  'только',\n",
              "  'потому',\n",
              "  ',',\n",
              "  'что',\n",
              "  'две',\n",
              "  'змееволосые',\n",
              "  'дамочки',\n",
              "  '(',\n",
              "  'они',\n",
              "  'называли',\n",
              "  'себя',\n",
              "  'горгонами',\n",
              "  ')',\n",
              "  'тоже',\n",
              "  ',',\n",
              "  'похоже',\n",
              "  ',',\n",
              "  'оказались',\n",
              "  'не',\n",
              "  'в',\n",
              "  'состоянии',\n",
              "  'его',\n",
              "  'убить',\n",
              "  '.'],\n",
              " ['Их', 'когти', 'не', 'оставляли', 'следа', 'на', 'его', 'коже', '.'],\n",
              " ['Если',\n",
              "  'они',\n",
              "  'пытались',\n",
              "  'его',\n",
              "  'укусить',\n",
              "  '–',\n",
              "  'зубы',\n",
              "  'у',\n",
              "  'них',\n",
              "  'ломались',\n",
              "  '.'],\n",
              " ['Но', 'Перси', 'уже', 'был', 'на', 'пределе', '.'],\n",
              " ['Скоро',\n",
              "  'он',\n",
              "  'свалится',\n",
              "  'от',\n",
              "  'истощения',\n",
              "  ',',\n",
              "  'а',\n",
              "  'тогда',\n",
              "  '…',\n",
              "  'хоть',\n",
              "  'его',\n",
              "  'и',\n",
              "  'трудно',\n",
              "  'убить',\n",
              "  ',',\n",
              "  'горгоны',\n",
              "  'найдут',\n",
              "  'способ',\n",
              "  '.'],\n",
              " ['Он', 'в', 'этом', 'не', 'сомневался', '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_sen_chunk_2 = n_sentenize(text2)\n",
        "n_sen_chunk_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFh2bRXUQ6LE",
        "outputId": "e836b529-383c-4a7a-ec2e-da0e2d2178fc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Сам',\n",
              "  'факт',\n",
              "  'Посещения',\n",
              "  'является',\n",
              "  'наиболее',\n",
              "  'важным',\n",
              "  'открытием',\n",
              "  'не',\n",
              "  'только',\n",
              "  'за',\n",
              "  'истекшие',\n",
              "  'тринадцать',\n",
              "  'лет',\n",
              "  ',',\n",
              "  'но',\n",
              "  'и',\n",
              "  'за',\n",
              "  'все',\n",
              "  'время',\n",
              "  'существования',\n",
              "  'человечества',\n",
              "  '.'],\n",
              " ['Не', 'так', 'уж', 'важно', ',', 'кто', 'были', 'эти', 'пришельцы', '.'],\n",
              " ['Неважно',\n",
              "  ',',\n",
              "  'откуда',\n",
              "  'они',\n",
              "  'прибыли',\n",
              "  ',',\n",
              "  'зачем',\n",
              "  'прибыли',\n",
              "  ',',\n",
              "  'почему',\n",
              "  'так',\n",
              "  'недолго',\n",
              "  'пробыли',\n",
              "  'и',\n",
              "  'куда',\n",
              "  'девались',\n",
              "  'потом',\n",
              "  '.'],\n",
              " ['Важно',\n",
              "  'то',\n",
              "  ',',\n",
              "  'что',\n",
              "  'теперь',\n",
              "  'человечество',\n",
              "  'твердо',\n",
              "  'знает',\n",
              "  ':',\n",
              "  'оно',\n",
              "  'не',\n",
              "  'одиноко',\n",
              "  'во',\n",
              "  'Вселенной',\n",
              "  '.'],\n",
              " ['Боюсь',\n",
              "  ',',\n",
              "  'что',\n",
              "  'Институту',\n",
              "  'Внеземных',\n",
              "  'Культур',\n",
              "  'уже',\n",
              "  'никогда',\n",
              "  'больше',\n",
              "  'не',\n",
              "  'повезет',\n",
              "  'сделать',\n",
              "  'более',\n",
              "  'фундаментальное',\n",
              "  'открытие',\n",
              "  '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Частеричная разметка (Part-Of-Speech tagging, POS-tagging)"
      ],
      "metadata": {
        "id": "Uscgyimj6LWQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В некоторых библиотеках вначале выполняется частеречная разметка, а далее на ее основе выполняется лемматизация."
      ],
      "metadata": {
        "id": "nzmwOM0RqNtF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spacy**"
      ],
      "metadata": {
        "id": "yOzIUkJzqTBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JGUPQbFLrOJN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import English\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "spacy_test = nlp(test_text)\n",
        "# from spacy.lang.ru import Russian\n",
        "# import spacy\n",
        "# nlp = spacy.load('ru_core_news_sm')\n",
        "# spacy_text = nlp(test_text)\n",
        "# spacy_text"
      ],
      "metadata": {
        "id": "kfuCP4tr6SQj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Просмотрим какие части речи присутсвуют в тестовом твите:"
      ],
      "metadata": {
        "id": "sNKuPH--6H_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in spacy_test:\n",
        "    print('{} - {} - {}'.format(token.text, token.pos_, token.dep_))"
      ],
      "metadata": {
        "id": "ZTfrFTBT6VIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fefcb300-146c-44b6-c12f-79eb62dd1412"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ранним - PROPN - nsubj\n",
            "майским - PROPN - compound\n",
            "утром - PROPN - ROOT\n",
            "к - NUM - compound\n",
            "гостинице - PROPN - dobj\n",
            "« - PROPN - dative\n",
            "Дубки - PROPN - nsubj\n",
            "» - PROPN - punct\n",
            "подкатил - NUM - ROOT\n",
            "светло - ADJ - compound\n",
            "- - PUNCT - punct\n",
            "серый - NOUN - compound\n",
            "автомобиль - NOUN - dobj\n",
            ". - PUNCT - punct\n",
            "Распахнулась - PROPN - compound\n",
            "дверца - NOUN - ROOT\n",
            ", - PUNCT - punct\n",
            "из - PROPN - compound\n",
            "машины - PROPN - compound\n",
            "выскочил - PROPN - compound\n",
            "человек - PROPN - compound\n",
            "с - PROPN - compound\n",
            "трубкой - PROPN - appos\n",
            "в - PROPN - compound\n",
            "зубах - NOUN - conj\n",
            ". - PUNCT - punct\n",
            "Увидев - PROPN - compound\n",
            "приветливые - PROPN - compound\n",
            "лица - PROPN - nsubj\n",
            ", - PUNCT - punct\n",
            "букеты - PROPN - compound\n",
            "цветов - PROPN - appos\n",
            ", - PUNCT - punct\n",
            "он - PROPN - ROOT\n",
            "смущённо - PROPN - compound\n",
            "улыбнулся - PROPN - pobj\n",
            ". - PUNCT - punct\n",
            "Это - PROPN - compound\n",
            "был - PROPN - nsubj\n",
            "профессор - NOUN - ROOT\n",
            "Громов - PROPN - appos\n",
            ". - PUNCT - punct\n",
            "Почётный - PROPN - compound\n",
            "гость - NOUN - compound\n",
            "конгресса - PROPN - compound\n",
            "кибернетиков - PROPN - compound\n",
            "приехал - PROPN - compound\n",
            "из - PROPN - compound\n",
            "Синегорска - PROPN - ROOT\n",
            ", - PUNCT - punct\n",
            "сибирского - PROPN - compound\n",
            "научного - PROPN - compound\n",
            "городка - PROPN - conj\n",
            ", - PUNCT - punct\n",
            "и - PROPN - conj\n",
            ", - PUNCT - punct\n",
            "как - PROPN - compound\n",
            "всегда - PROPN - appos\n",
            ", - PUNCT - punct\n",
            "решил - PROPN - nsubj\n",
            "остановиться - PROPN - ROOT\n",
            "в - PROPN - det\n",
            "« - NOUN - compound\n",
            "Дубках - PROPN - dobj\n",
            "» - PUNCT - punct\n",
            ". - PUNCT - punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Natasha**"
      ],
      "metadata": {
        "id": "v1dpbny7uJVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from navec import Navec\n",
        "from slovnet import Morph"
      ],
      "metadata": {
        "id": "dWlwA9EjQ-Gx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Файл необходимо скачать по ссылке https://github.com/natasha/navec#downloads\n",
        "navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')"
      ],
      "metadata": {
        "id": "A56s0v6KREM5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Файл необходимо скачать по ссылке https://github.com/natasha/slovnet#downloads\n",
        "n_morph = Morph.load('slovnet_morph_news_v1.tar', batch_size=4)"
      ],
      "metadata": {
        "id": "8URHHeoERExt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "morph_res = n_morph.navec(navec)"
      ],
      "metadata": {
        "id": "8OekmhyiRNit"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_pos(markup):\n",
        "    for token in markup.tokens:\n",
        "        print('{} - {}'.format(token.text, token.tag))"
      ],
      "metadata": {
        "id": "5QYBE8gORYS9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_text_markup = list(_ for _ in n_morph.map(n_sen_chunk))\n",
        "[print_pos(x) for x in n_text_markup]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xlv5OaGGRY0H",
        "outputId": "f49cfb1c-2656-4c72-b39c-8384d92e757b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эти - DET|Case=Nom|Number=Plur\n",
            "змееволосые - ADJ|Case=Nom|Degree=Pos|Number=Plur\n",
            "дамочки - NOUN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Plur\n",
            "уже - ADV|Degree=Pos\n",
            "начали - VERB|Aspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "раздражать - VERB|Aspect=Imp|VerbForm=Inf|Voice=Act\n",
            "Перси - PROPN|Animacy=Anim|Case=Acc|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "Они - PRON|Case=Nom|Number=Plur|Person=3\n",
            "должны - ADJ|Degree=Pos|Number=Plur|Variant=Short\n",
            "были - AUX|Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "умереть - VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            "еще - ADV|Degree=Pos\n",
            "три - NUM|Animacy=Inan|Case=Acc\n",
            "дня - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "назад - ADV|Degree=Pos\n",
            ", - PUNCT\n",
            "когда - SCONJ\n",
            "он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            "сбросил - VERB|Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "на - ADP\n",
            "них - PRON|Animacy=Inan|Case=Acc|Number=Plur|Person=3\n",
            "ящик - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
            "с - ADP\n",
            "шарами - NOUN|Animacy=Inan|Case=Ins|Gender=Fem|Number=Plur\n",
            "для - ADP\n",
            "боулинга - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "в - ADP\n",
            "« - PUNCT\n",
            "Баргин-Марте - NOUN|Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing\n",
            "» - PUNCT\n",
            "в - ADP\n",
            "Напе - PROPN|Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "Они - PRON|Case=Nom|Number=Plur|Person=3\n",
            "должны - ADJ|Degree=Pos|Number=Plur|Variant=Short\n",
            "были - AUX|Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "отдать - VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            "концы - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Plur\n",
            "два - NUM|Animacy=Inan|Case=Acc|Gender=Masc\n",
            "дня - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "назад - ADV|Degree=Pos\n",
            ", - PUNCT\n",
            "после - ADP\n",
            "того - PRON|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            "как - SCONJ\n",
            "он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            "переехал - VERB|Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "их - PRON|Animacy=Inan|Case=Acc|Number=Plur|Person=3\n",
            "полицейским - ADJ|Case=Ins|Degree=Pos|Gender=Masc|Number=Sing\n",
            "автомобилем - NOUN|Animacy=Inan|Case=Ins|Gender=Masc|Number=Sing\n",
            "в - ADP\n",
            "Мартинесе - PROPN|Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "И - CCONJ\n",
            "уж - PART\n",
            "точно - ADV|Degree=Pos\n",
            "они - PRON|Case=Nom|Number=Plur|Person=3\n",
            "должны - ADJ|Degree=Pos|Number=Plur|Variant=Short\n",
            "были - AUX|Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "сдохнуть - VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            ", - PUNCT\n",
            "когда - SCONJ\n",
            "он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            "отрезал - VERB|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "им - PRON|Case=Dat|Number=Plur|Person=3\n",
            "головы - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Plur\n",
            "сегодня - ADV|Degree=Pos\n",
            "утром - NOUN|Animacy=Inan|Case=Ins|Gender=Neut|Number=Sing\n",
            "в - ADP\n",
            "Тилден-парке - PROPN|Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "Перси - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "убивал - VERB|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "их - PRON|Animacy=Inan|Case=Acc|Number=Plur|Person=3\n",
            "и - CCONJ\n",
            "своими - DET|Case=Ins|Number=Plur\n",
            "глазами - NOUN|Animacy=Inan|Case=Ins|Gender=Masc|Number=Plur\n",
            "видел - VERB|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            ", - PUNCT\n",
            "как - SCONJ\n",
            "они - PRON|Case=Nom|Number=Plur|Person=3\n",
            "обращаются - VERB|Aspect=Imp|Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin|Voice=Mid\n",
            "в - ADP\n",
            "прах - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
            ", - PUNCT\n",
            "но - CCONJ\n",
            "эти - DET|Case=Nom|Number=Plur\n",
            "гнусные - ADJ|Case=Nom|Degree=Pos|Number=Plur\n",
            "тетки - NOUN|Animacy=Anim|Case=Nom|Gender=Fem|Number=Plur\n",
            "неизменно - ADV|Degree=Pos\n",
            "возвращались - VERB|Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Mid\n",
            "к - ADP\n",
            "жизни - NOUN|Animacy=Inan|Case=Dat|Gender=Fem|Number=Sing\n",
            ". - PUNCT\n",
            "Он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            ", - PUNCT\n",
            "похоже - ADV|Degree=Pos\n",
            ", - PUNCT\n",
            "даже - PART\n",
            "не - PART|Polarity=Neg\n",
            "мог - VERB|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "надолго - ADV|Degree=Pos\n",
            "от - ADP\n",
            "них - PRON|Case=Gen|Number=Plur|Person=3\n",
            "оторваться - VERB|Aspect=Perf|VerbForm=Inf|Voice=Mid\n",
            ". - PUNCT\n",
            "Он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            "взобрался - VERB|Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid\n",
            "на - ADP\n",
            "вершину - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
            "холма - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "и - CCONJ\n",
            "перевел - VERB|Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "дух - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "Сколько - NUM|Animacy=Inan|Case=Acc\n",
            "времени - NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            "прошло - VERB|Aspect=Perf|Gender=Neut|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "с - ADP\n",
            "тех - DET|Case=Gen|Number=Plur\n",
            "пор - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur\n",
            ", - PUNCT\n",
            "как - SCONJ\n",
            "он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            "прикончил - VERB|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "их - PRON|Animacy=Inan|Case=Acc|Number=Plur|Person=3\n",
            "в - ADP\n",
            "последний - ADJ|Animacy=Inan|Case=Acc|Degree=Pos|Gender=Masc|Number=Sing\n",
            "раз - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
            "? - PUNCT\n",
            "Часа - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "два - NUM|Case=Nom|Gender=Masc\n",
            ", - PUNCT\n",
            "наверное - ADV|Degree=Pos\n",
            ". - PUNCT\n",
            "Кажется - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Mid\n",
            ", - PUNCT\n",
            "они - PRON|Case=Nom|Number=Plur|Person=3\n",
            "теперь - ADV|Degree=Pos\n",
            "не - PART|Polarity=Neg\n",
            "умирают - VERB|Aspect=Imp|Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            "больше - ADV|Degree=Cmp\n",
            "чем - SCONJ\n",
            "на - ADP\n",
            "два - NUM|Animacy=Inan|Case=Acc|Gender=Masc\n",
            "часа - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "… - PUNCT\n",
            "В - ADP\n",
            "последние - ADJ|Animacy=Inan|Case=Acc|Degree=Pos|Number=Plur\n",
            "дни - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Plur\n",
            "Перси - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "почти - ADV|Degree=Pos\n",
            "не - PART|Polarity=Neg\n",
            "спал - VERB|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            ". - PUNCT\n",
            "Ел - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            "то - PRON|Animacy=Inan|Case=Acc|Gender=Neut|Number=Sing\n",
            ", - PUNCT\n",
            "что - SCONJ\n",
            "удавалось - VERB|Aspect=Imp|Gender=Neut|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid\n",
            "стянуть - VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            "по - ADP\n",
            "дороге - NOUN|Animacy=Inan|Case=Dat|Gender=Fem|Number=Sing\n",
            ", - PUNCT\n",
            "– - PUNCT\n",
            "жевательную - ADJ|Case=Acc|Degree=Pos|Gender=Fem|Number=Sing\n",
            "конфету - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
            "из - ADP\n",
            "торгового - ADJ|Case=Gen|Degree=Pos|Gender=Masc|Number=Sing\n",
            "автомата - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            ", - PUNCT\n",
            "черствый - VERB|Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "бублик - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
            "или - CCONJ\n",
            "лепешку - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
            "буррито - NOUN|Animacy=Inan|Case=Ins|Gender=Masc|Number=Sing\n",
            ", - PUNCT\n",
            "хотя - SCONJ\n",
            "прежде - ADV|Degree=Pos\n",
            "он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            "еще - ADV|Degree=Pos\n",
            "так - ADV|Degree=Pos\n",
            "низко - ADV|Degree=Pos\n",
            "не - PART|Polarity=Neg\n",
            "опускался - VERB|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid\n",
            ". - PUNCT\n",
            "Одежда - NOUN|Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing\n",
            "его - PRON|Case=Gen|Gender=Masc|Number=Sing|Person=3\n",
            "порвалась - NOUN|Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing\n",
            ", - PUNCT\n",
            "местами - NOUN|Animacy=Inan|Case=Ins|Gender=Neut|Number=Plur\n",
            "обгорела - NOUN|Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing\n",
            "и - CCONJ\n",
            "вся - DET|Case=Nom|Gender=Fem|Number=Sing\n",
            "была - AUX|Aspect=Imp|Gender=Fem|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "заляпана - VERB|Aspect=Perf|Gender=Fem|Number=Sing|Tense=Past|Variant=Short|VerbForm=Part|Voice=Pass\n",
            "слюной - NOUN|Animacy=Inan|Case=Ins|Gender=Fem|Number=Sing\n",
            "монстров - NOUN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Plur\n",
            ". - PUNCT\n",
            "Перси - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "до - ADP\n",
            "сих - DET|Case=Gen|Number=Plur\n",
            "пор - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur\n",
            "был - AUX|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "жив - ADJ|Degree=Pos|Gender=Masc|Number=Sing|Variant=Short\n",
            "только - PART\n",
            "потому - ADV|Degree=Pos\n",
            ", - PUNCT\n",
            "что - SCONJ\n",
            "две - NUM|Case=Nom|Gender=Fem\n",
            "змееволосые - ADJ|Case=Nom|Degree=Pos|Number=Plur\n",
            "дамочки - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "( - PUNCT\n",
            "они - PRON|Case=Nom|Number=Plur|Person=3\n",
            "называли - VERB|Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "себя - PRON|Case=Acc\n",
            "горгонами - NOUN|Animacy=Anim|Case=Ins|Gender=Masc|Number=Plur\n",
            ") - PUNCT\n",
            "тоже - ADV|Degree=Pos\n",
            ", - PUNCT\n",
            "похоже - ADV|Degree=Pos\n",
            ", - PUNCT\n",
            "оказались - VERB|Aspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Mid\n",
            "не - PART|Polarity=Neg\n",
            "в - ADP\n",
            "состоянии - NOUN|Animacy=Inan|Case=Loc|Gender=Neut|Number=Sing\n",
            "его - PRON|Case=Acc|Gender=Masc|Number=Sing|Person=3\n",
            "убить - VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            ". - PUNCT\n",
            "Их - DET\n",
            "когти - NOUN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Plur\n",
            "не - PART|Polarity=Neg\n",
            "оставляли - VERB|Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "следа - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "на - ADP\n",
            "его - DET\n",
            "коже - NOUN|Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing\n",
            ". - PUNCT\n",
            "Если - SCONJ\n",
            "они - PRON|Case=Nom|Number=Plur|Person=3\n",
            "пытались - VERB|Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Mid\n",
            "его - PRON|Case=Acc|Gender=Masc|Number=Sing|Person=3\n",
            "укусить - VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            "– - PUNCT\n",
            "зубы - NOUN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Plur\n",
            "у - ADP\n",
            "них - PRON|Case=Gen|Number=Plur|Person=3\n",
            "ломались - VERB|Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            ". - PUNCT\n",
            "Но - CCONJ\n",
            "Перси - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "уже - ADV|Degree=Pos\n",
            "был - AUX|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "на - ADP\n",
            "пределе - NOUN|Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "Скоро - ADV|Degree=Pos\n",
            "он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            "свалится - VERB|Aspect=Perf|Mood=Ind|Number=Sing|Person=3|Tense=Fut|VerbForm=Fin|Voice=Mid\n",
            "от - ADP\n",
            "истощения - NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            ", - PUNCT\n",
            "а - CCONJ\n",
            "тогда - ADV|Degree=Pos\n",
            "… - PUNCT\n",
            "хоть - ADV|Degree=Pos\n",
            "его - PRON|Case=Acc|Gender=Masc|Number=Sing|Person=3\n",
            "и - CCONJ\n",
            "трудно - ADJ|Degree=Pos|Gender=Neut|Number=Sing|Variant=Short\n",
            "убить - VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            ", - PUNCT\n",
            "горгоны - NOUN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Plur\n",
            "найдут - VERB|Aspect=Perf|Mood=Ind|Number=Plur|Person=3|Tense=Fut|VerbForm=Fin|Voice=Act\n",
            "способ - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "Он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            "в - ADP\n",
            "этом - PRON|Animacy=Inan|Case=Loc|Gender=Neut|Number=Sing\n",
            "не - PART|Polarity=Neg\n",
            "сомневался - VERB|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid\n",
            ". - PUNCT\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_text2_markup = list(n_morph.map(n_sen_chunk_2))\n",
        "[print_pos(x) for x in n_text2_markup]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf1e4LOkRcHI",
        "outputId": "88c1cf6f-cbcb-4611-b8f8-448f47b690f2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сам - ADJ|Case=Nom|Degree=Pos|Gender=Masc|Number=Sing\n",
            "факт - NOUN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
            "Посещения - PROPN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            "является - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Mid\n",
            "наиболее - ADV|Degree=Pos\n",
            "важным - ADJ|Case=Ins|Degree=Pos|Gender=Neut|Number=Sing\n",
            "открытием - NOUN|Animacy=Inan|Case=Ins|Gender=Neut|Number=Sing\n",
            "не - PART|Polarity=Neg\n",
            "только - PART\n",
            "за - ADP\n",
            "истекшие - VERB|Animacy=Inan|Aspect=Perf|Case=Acc|Number=Plur|Tense=Past|VerbForm=Part|Voice=Act\n",
            "тринадцать - NUM|Case=Acc\n",
            "лет - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Plur\n",
            ", - PUNCT\n",
            "но - CCONJ\n",
            "и - CCONJ\n",
            "за - ADP\n",
            "все - DET|Animacy=Inan|Case=Acc|Gender=Neut|Number=Sing\n",
            "время - NOUN|Animacy=Inan|Case=Acc|Gender=Neut|Number=Sing\n",
            "существования - NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            "человечества - NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            ". - PUNCT\n",
            "Не - PART|Polarity=Neg\n",
            "так - ADV|Degree=Pos\n",
            "уж - PART\n",
            "важно - ADJ|Degree=Pos|Gender=Neut|Number=Sing|Variant=Short\n",
            ", - PUNCT\n",
            "кто - PRON|Case=Nom\n",
            "были - AUX|Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "эти - DET|Case=Nom|Number=Plur\n",
            "пришельцы - NOUN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Plur\n",
            ". - PUNCT\n",
            "Неважно - ADV|Degree=Pos\n",
            ", - PUNCT\n",
            "откуда - ADV|Degree=Pos\n",
            "они - PRON|Case=Nom|Number=Plur|Person=3\n",
            "прибыли - VERB|Aspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            ", - PUNCT\n",
            "зачем - ADV|Degree=Pos\n",
            "прибыли - VERB|Aspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            ", - PUNCT\n",
            "почему - ADV|Degree=Pos\n",
            "так - ADV|Degree=Pos\n",
            "недолго - ADV|Degree=Pos\n",
            "пробыли - VERB|Aspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "и - CCONJ\n",
            "куда - ADV|Degree=Pos\n",
            "девались - VERB|Aspect=Perf|Mood=Ind|Number=Plur|Person=3|Tense=Fut|VerbForm=Fin|Voice=Act\n",
            "потом - ADV|Degree=Pos\n",
            ". - PUNCT\n",
            "Важно - ADJ|Degree=Pos|Gender=Neut|Number=Sing|Variant=Short\n",
            "то - PRON|Animacy=Inan|Case=Nom|Gender=Neut|Number=Sing\n",
            ", - PUNCT\n",
            "что - SCONJ\n",
            "теперь - ADV|Degree=Pos\n",
            "человечество - NOUN|Animacy=Inan|Case=Nom|Gender=Neut|Number=Sing\n",
            "твердо - ADV|Degree=Pos\n",
            "знает - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            ": - PUNCT\n",
            "оно - PRON|Case=Nom|Gender=Neut|Number=Sing|Person=3\n",
            "не - PART|Polarity=Neg\n",
            "одиноко - ADV|Degree=Pos\n",
            "во - ADP\n",
            "Вселенной - PROPN|Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing\n",
            ". - PUNCT\n",
            "Боюсь - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|Voice=Mid\n",
            ", - PUNCT\n",
            "что - SCONJ\n",
            "Институту - PROPN|Animacy=Inan|Case=Dat|Gender=Masc|Number=Sing\n",
            "Внеземных - ADJ|Case=Gen|Degree=Pos|Number=Plur\n",
            "Культур - PROPN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Plur\n",
            "уже - ADV|Degree=Pos\n",
            "никогда - ADV|Degree=Pos\n",
            "больше - ADV|Degree=Cmp\n",
            "не - PART|Polarity=Neg\n",
            "повезет - VERB|Aspect=Perf|Mood=Ind|Number=Sing|Person=3|Tense=Fut|VerbForm=Fin|Voice=Act\n",
            "сделать - VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            "более - ADV|Degree=Cmp\n",
            "фундаментальное - ADJ|Animacy=Inan|Case=Acc|Degree=Pos|Gender=Neut|Number=Sing\n",
            "открытие - NOUN|Animacy=Inan|Case=Acc|Gender=Neut|Number=Sing\n",
            ". - PUNCT\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Лемматизация"
      ],
      "metadata": {
        "id": "eWP6ezDc6aE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spacy**"
      ],
      "metadata": {
        "id": "5a-o2y_LvKlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in spacy_test:\n",
        "      print(token, token.lemma, token.lemma_)"
      ],
      "metadata": {
        "id": "bSc_XMaw6dBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64a0b6af-2457-4509-8e3c-33082e518bc3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ранним 8960284696763509766 Ранним\n",
            "майским 4860452770365339605 майским\n",
            "утром 10406298982460915654 утром\n",
            "к 2390146911029080849 к\n",
            "гостинице 3427631985009736557 гостинице\n",
            "« 1373379536816847062 «\n",
            "Дубки 16767377834009918285 Дубки\n",
            "» 5342463183827332990 »\n",
            "подкатил 15889380949265465631 подкатил\n",
            "светло 10403397017051258397 светло\n",
            "- 9153284864653046197 -\n",
            "серый 293004198024914368 серый\n",
            "автомобиль 15690161355021272870 автомобиль\n",
            ". 12646065887601541794 .\n",
            "Распахнулась 15035480498679999475 Распахнулась\n",
            "дверца 8347868081549859214 дверца\n",
            ", 2593208677638477497 ,\n",
            "из 12183146372738139588 из\n",
            "машины 3574605372934986972 машины\n",
            "выскочил 5965066048200716231 выскочил\n",
            "человек 7568775649844232870 человек\n",
            "с 5863529159893111856 с\n",
            "трубкой 1271733369831796785 трубкой\n",
            "в 15939375860797385675 в\n",
            "зубах 14663926127362700491 зубах\n",
            ". 12646065887601541794 .\n",
            "Увидев 6663573993513292520 Увидев\n",
            "приветливые 10667803453304488442 приветливые\n",
            "лица 16981797281768476569 лица\n",
            ", 2593208677638477497 ,\n",
            "букеты 16972093218046880272 букеты\n",
            "цветов 14705294268059991987 цветов\n",
            ", 2593208677638477497 ,\n",
            "он 7004339974413567607 он\n",
            "смущённо 2889550843480277746 смущённо\n",
            "улыбнулся 8846738030547974580 улыбнулся\n",
            ". 12646065887601541794 .\n",
            "Это 6166395895414128982 Это\n",
            "был 647519599663180051 был\n",
            "профессор 18094890929148750994 профессор\n",
            "Громов 2850279829997148809 Громов\n",
            ". 12646065887601541794 .\n",
            "Почётный 1467091420853914851 Почётный\n",
            "гость 2806713705785072619 гость\n",
            "конгресса 7106661838159002761 конгресса\n",
            "кибернетиков 13534226636079181325 кибернетиков\n",
            "приехал 7222518665697276410 приехал\n",
            "из 12183146372738139588 из\n",
            "Синегорска 5451488223726882187 Синегорска\n",
            ", 2593208677638477497 ,\n",
            "сибирского 13276346775445981270 сибирского\n",
            "научного 8738816006371375365 научного\n",
            "городка 9201303923069401183 городка\n",
            ", 2593208677638477497 ,\n",
            "и 15015917632809974589 и\n",
            ", 2593208677638477497 ,\n",
            "как 13039644133688645009 как\n",
            "всегда 10633257961924346802 всегда\n",
            ", 2593208677638477497 ,\n",
            "решил 18242611503851558175 решил\n",
            "остановиться 5707673703628731919 остановиться\n",
            "в 15939375860797385675 в\n",
            "« 1373379536816847062 «\n",
            "Дубках 6201723511842712495 Дубках\n",
            "» 5342463183827332990 »\n",
            ". 12646065887601541794 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Natasha**"
      ],
      "metadata": {
        "id": "zXk8-GBkvF2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from natasha import Doc, Segmenter, NewsEmbedding, NewsMorphTagger, MorphVocab"
      ],
      "metadata": {
        "id": "FuySXFnRTHLL"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def n_lemmatize(text):\n",
        "    emb = NewsEmbedding()\n",
        "    morph_tagger = NewsMorphTagger(emb)\n",
        "    segmenter = Segmenter()\n",
        "    morph_vocab = MorphVocab()\n",
        "    doc = Doc(text)\n",
        "    doc.segment(segmenter)\n",
        "    doc.tag_morph(morph_tagger)\n",
        "    for token in doc.tokens:\n",
        "        token.lemmatize(morph_vocab)\n",
        "    return doc"
      ],
      "metadata": {
        "id": "oodcjl3LTJTJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_doc = n_lemmatize(text)\n",
        "{_.text: _.lemma for _ in n_doc.tokens}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uzjf5dRGTLag",
        "outputId": "278851b8-1c53-402a-a52d-1edd98472cc1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'(': '(',\n",
              " ')': ')',\n",
              " ',': ',',\n",
              " '.': '.',\n",
              " '?': '?',\n",
              " '«': '«',\n",
              " '»': '»',\n",
              " 'Баргин-Марте': 'баргин-марта',\n",
              " 'В': 'в',\n",
              " 'Ел': 'есть',\n",
              " 'Если': 'если',\n",
              " 'И': 'и',\n",
              " 'Их': 'их',\n",
              " 'Кажется': 'казаться',\n",
              " 'Мартинесе': 'мартинес',\n",
              " 'Напе': 'напе',\n",
              " 'Но': 'но',\n",
              " 'Одежда': 'одежда',\n",
              " 'Он': 'он',\n",
              " 'Они': 'они',\n",
              " 'Перси': 'перси',\n",
              " 'Сколько': 'сколько',\n",
              " 'Скоро': 'скоро',\n",
              " 'Тилден-парке': 'тилден-парк',\n",
              " 'Часа': 'час',\n",
              " 'Эти': 'этот',\n",
              " 'а': 'а',\n",
              " 'автомата': 'автомат',\n",
              " 'автомобилем': 'автомобиль',\n",
              " 'больше': 'большой',\n",
              " 'боулинга': 'боулинг',\n",
              " 'бублик': 'бублик',\n",
              " 'буррито': 'буррито',\n",
              " 'был': 'быть',\n",
              " 'была': 'быть',\n",
              " 'были': 'быть',\n",
              " 'в': 'в',\n",
              " 'вершину': 'вершина',\n",
              " 'взобрался': 'взобраться',\n",
              " 'видел': 'видеть',\n",
              " 'возвращались': 'возвращаться',\n",
              " 'времени': 'время',\n",
              " 'вся': 'весь',\n",
              " 'глазами': 'глаз',\n",
              " 'гнусные': 'гнусный',\n",
              " 'головы': 'голова',\n",
              " 'горгонами': 'горгон',\n",
              " 'горгоны': 'горгон',\n",
              " 'даже': 'даже',\n",
              " 'дамочки': 'дамочка',\n",
              " 'два': 'два',\n",
              " 'две': 'два',\n",
              " 'для': 'для',\n",
              " 'дни': 'день',\n",
              " 'дня': 'день',\n",
              " 'до': 'до',\n",
              " 'должны': 'должный',\n",
              " 'дороге': 'дорога',\n",
              " 'дух': 'дух',\n",
              " 'его': 'он',\n",
              " 'еще': 'еще',\n",
              " 'жевательную': 'жевательный',\n",
              " 'жив': 'живой',\n",
              " 'жизни': 'жизнь',\n",
              " 'заляпана': 'заляпать',\n",
              " 'змееволосые': 'змееволосый',\n",
              " 'зубы': 'зуб',\n",
              " 'и': 'и',\n",
              " 'из': 'из',\n",
              " 'или': 'или',\n",
              " 'им': 'они',\n",
              " 'истощения': 'истощение',\n",
              " 'их': 'они',\n",
              " 'к': 'к',\n",
              " 'как': 'как',\n",
              " 'когда': 'когда',\n",
              " 'когти': 'коготь',\n",
              " 'коже': 'кожа',\n",
              " 'конфету': 'конфета',\n",
              " 'концы': 'конец',\n",
              " 'лепешку': 'лепешка',\n",
              " 'ломались': 'ломаться',\n",
              " 'местами': 'место',\n",
              " 'мог': 'мочь',\n",
              " 'монстров': 'монстр',\n",
              " 'на': 'на',\n",
              " 'наверное': 'наверное',\n",
              " 'надолго': 'надолго',\n",
              " 'назад': 'назад',\n",
              " 'называли': 'называть',\n",
              " 'найдут': 'найти',\n",
              " 'начали': 'начать',\n",
              " 'не': 'не',\n",
              " 'неизменно': 'неизменно',\n",
              " 'низко': 'низко',\n",
              " 'них': 'они',\n",
              " 'но': 'но',\n",
              " 'обгорела': 'обгореть',\n",
              " 'обращаются': 'обращаться',\n",
              " 'оказались': 'оказаться',\n",
              " 'он': 'он',\n",
              " 'они': 'они',\n",
              " 'опускался': 'опускаться',\n",
              " 'оставляли': 'оставлять',\n",
              " 'от': 'от',\n",
              " 'отдать': 'отдать',\n",
              " 'оторваться': 'оторваться',\n",
              " 'отрезал': 'отрезать',\n",
              " 'перевел': 'перевести',\n",
              " 'переехал': 'переехать',\n",
              " 'по': 'по',\n",
              " 'полицейским': 'полицейский',\n",
              " 'пор': 'пора',\n",
              " 'порвалась': 'порваться',\n",
              " 'после': 'после',\n",
              " 'последние': 'последний',\n",
              " 'последний': 'последний',\n",
              " 'потому': 'потому',\n",
              " 'похоже': 'похоже',\n",
              " 'почти': 'почти',\n",
              " 'прах': 'прах',\n",
              " 'пределе': 'предел',\n",
              " 'прежде': 'прежде',\n",
              " 'прикончил': 'прикончить',\n",
              " 'прошло': 'пройти',\n",
              " 'пытались': 'пытаться',\n",
              " 'раз': 'раз',\n",
              " 'раздражать': 'раздражать',\n",
              " 'с': 'с',\n",
              " 'сбросил': 'сбросить',\n",
              " 'свалится': 'свалиться',\n",
              " 'своими': 'свой',\n",
              " 'сдохнуть': 'сдохнуть',\n",
              " 'себя': 'себя',\n",
              " 'сегодня': 'сегодня',\n",
              " 'сих': 'сей',\n",
              " 'следа': 'след',\n",
              " 'слюной': 'слюна',\n",
              " 'сомневался': 'сомневаться',\n",
              " 'состоянии': 'состояние',\n",
              " 'спал': 'спать',\n",
              " 'способ': 'способ',\n",
              " 'стянуть': 'стянуть',\n",
              " 'так': 'так',\n",
              " 'теперь': 'теперь',\n",
              " 'тетки': 'тетка',\n",
              " 'тех': 'тот',\n",
              " 'то': 'тот',\n",
              " 'тогда': 'тогда',\n",
              " 'того': 'тот',\n",
              " 'тоже': 'тоже',\n",
              " 'только': 'только',\n",
              " 'торгового': 'торговый',\n",
              " 'точно': 'точно',\n",
              " 'три': 'три',\n",
              " 'трудно': 'трудный',\n",
              " 'у': 'у',\n",
              " 'убивал': 'убивать',\n",
              " 'убить': 'убить',\n",
              " 'удавалось': 'удаваться',\n",
              " 'уж': 'уж',\n",
              " 'уже': 'уже',\n",
              " 'укусить': 'укусить',\n",
              " 'умереть': 'умереть',\n",
              " 'умирают': 'умирать',\n",
              " 'утром': 'утро',\n",
              " 'холма': 'холм',\n",
              " 'хоть': 'хоть',\n",
              " 'хотя': 'хотя',\n",
              " 'часа': 'час',\n",
              " 'чем': 'чем',\n",
              " 'черствый': 'черствый',\n",
              " 'что': 'что',\n",
              " 'шарами': 'шар',\n",
              " 'эти': 'этот',\n",
              " 'этом': 'это',\n",
              " 'ящик': 'ящик',\n",
              " '–': '–',\n",
              " '…': '…'}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_doc2 = n_lemmatize(text2)\n",
        "{_.text: _.lemma for _ in n_doc2.tokens}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxBRWEXETPh3",
        "outputId": "2a76b92b-90ab-4d8e-f195-93954b8da485"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{',': ',',\n",
              " '.': '.',\n",
              " ':': ':',\n",
              " 'Боюсь': 'бояться',\n",
              " 'Важно': 'важный',\n",
              " 'Внеземных': 'внеземной',\n",
              " 'Вселенной': 'вселенная',\n",
              " 'Институту': 'институт',\n",
              " 'Культур': 'культура',\n",
              " 'Не': 'не',\n",
              " 'Неважно': 'неважно',\n",
              " 'Посещения': 'посещение',\n",
              " 'Сам': 'сам',\n",
              " 'более': 'более',\n",
              " 'больше': 'большой',\n",
              " 'были': 'быть',\n",
              " 'важно': 'важный',\n",
              " 'важным': 'важный',\n",
              " 'во': 'в',\n",
              " 'время': 'время',\n",
              " 'все': 'весь',\n",
              " 'девались': 'деваться',\n",
              " 'за': 'за',\n",
              " 'зачем': 'зачем',\n",
              " 'знает': 'знать',\n",
              " 'и': 'и',\n",
              " 'истекшие': 'истечь',\n",
              " 'кто': 'кто',\n",
              " 'куда': 'куда',\n",
              " 'лет': 'год',\n",
              " 'наиболее': 'наиболее',\n",
              " 'не': 'не',\n",
              " 'недолго': 'недолго',\n",
              " 'никогда': 'никогда',\n",
              " 'но': 'но',\n",
              " 'одиноко': 'одиноко',\n",
              " 'они': 'они',\n",
              " 'оно': 'оно',\n",
              " 'открытие': 'открытие',\n",
              " 'открытием': 'открытие',\n",
              " 'откуда': 'откуда',\n",
              " 'повезет': 'повезти',\n",
              " 'потом': 'потом',\n",
              " 'почему': 'почему',\n",
              " 'прибыли': 'прибыть',\n",
              " 'пришельцы': 'пришелец',\n",
              " 'пробыли': 'пробыть',\n",
              " 'сделать': 'сделать',\n",
              " 'существования': 'существование',\n",
              " 'так': 'так',\n",
              " 'твердо': 'твердо',\n",
              " 'теперь': 'теперь',\n",
              " 'то': 'тот',\n",
              " 'только': 'только',\n",
              " 'тринадцать': 'тринадцать',\n",
              " 'уж': 'уж',\n",
              " 'уже': 'уже',\n",
              " 'факт': 'факт',\n",
              " 'фундаментальное': 'фундаментальный',\n",
              " 'человечества': 'человечество',\n",
              " 'человечество': 'человечество',\n",
              " 'что': 'что',\n",
              " 'эти': 'этот',\n",
              " 'является': 'являться'}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выделение (распознавание) именованных сущностей, named-entity recognition (NER)"
      ],
      "metadata": {
        "id": "xzt6FOTE6YhS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spacy**"
      ],
      "metadata": {
        "id": "MSX-GdtIvgJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in spacy_test.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "id": "elJZ4cNi6jSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd6f9be-7ab0-41d7-a060-c0bb070c814b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Дубки ORG\n",
            "выскочил человек PERSON\n",
            "лица ORG\n",
            "Это ORG\n",
            "Громов ORG\n",
            "Почётный гость PERSON\n",
            "кибернетиков приехал PERSON\n",
            "Синегорска PRODUCT\n",
            "сибирского научного городка ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spacy.explain(\"ORDINAL\"))"
      ],
      "metadata": {
        "id": "nzDwTR9u6lVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364a2574-9e90-4bf6-cffa-63ef5af860a7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"first\", \"second\", etc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spacy.explain(\"PRODUCT\"))"
      ],
      "metadata": {
        "id": "6m_kq2DR6n7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "599dc684-b2d9-45a6-c676-73216d356d7d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Objects, vehicles, foods, etc. (not services)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spacy.explain(\"LOC\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcUfuAtywA2D",
        "outputId": "a8716e64-fdce-4e4b-dfd1-0f0873d670c8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-GPE locations, mountain ranges, bodies of water\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spacy.explain(\"PER\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuhDw6-ZwCrq",
        "outputId": "8c078701-a5ce-4959-ec0e-588cf9a09cd5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named person or family.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "displacy.render(spacy_test, style='ent', jupyter=True)"
      ],
      "metadata": {
        "id": "BUmx3tiP6qWL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "ab28f94e-a33c-4a04-a545-76b0c7cdad5c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Ранним майским утром к гостинице «\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Дубки\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "» подкатил светло-серый автомобиль. Распахнулась дверца, из машины \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    выскочил человек\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " с трубкой в зубах. Увидев приветливые \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    лица\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", букеты цветов, он смущённо улыбнулся. \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Это\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " был профессор \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Громов\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ". \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Почётный гость\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " конгресса \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    кибернетиков приехал\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " из \n",
              "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Синегорска\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    сибирского научного городка\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", и, как всегда, решил остановиться в «Дубках».</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Natasha**"
      ],
      "metadata": {
        "id": "TtXrGtU1wNJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from slovnet import NER\n",
        "from ipymarkup import show_span_ascii_markup as show_markup"
      ],
      "metadata": {
        "id": "k71MCf2uTTQ6"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner = NER.load('slovnet_ner_news_v1.tar')"
      ],
      "metadata": {
        "id": "IBmhEnBVTUFC"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_res = ner.navec(navec)"
      ],
      "metadata": {
        "id": "1Xpqt132Tvc_"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markup_ner = ner(text2)\n",
        "markup_ner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAg6lE7NTxUQ",
        "outputId": "e2db7ec6-fe27-4c10-a48f-5ebf64670d99"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SpanMarkup(\n",
              "    text='Сам факт Посещения является наиболее важным открытием не только за истекшие тринадцать лет, но и за все время существования человечества. Не так уж важно, кто были эти пришельцы. Неважно, откуда они прибыли, зачем прибыли, почему так недолго пробыли и куда девались потом. Важно то, что теперь человечество твердо знает: оно не одиноко во Вселенной. Боюсь, что Институту Внеземных Культур уже никогда больше не повезет сделать более фундаментальное открытие.',\n",
              "    spans=[Span(\n",
              "         start=9,\n",
              "         stop=18,\n",
              "         type='LOC'\n",
              "     ), Span(\n",
              "         start=361,\n",
              "         stop=388,\n",
              "         type='ORG'\n",
              "     )]\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_markup(markup_ner.text, markup_ner.spans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wyy5je16Tx8b",
        "outputId": "6ecadc31-9cff-4cc2-8767-fab5b8df6b09"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сам факт Посещения является наиболее важным открытием не только за \n",
            "         LOC──────                                                 \n",
            "истекшие тринадцать лет, но и за все время существования человечества.\n",
            " Не так уж важно, кто были эти пришельцы. Неважно, откуда они прибыли,\n",
            " зачем прибыли, почему так недолго пробыли и куда девались потом. \n",
            "Важно то, что теперь человечество твердо знает: оно не одиноко во \n",
            "Вселенной. Боюсь, что Институту Внеземных Культур уже никогда больше \n",
            "                      ORG────────────────────────                    \n",
            "не повезет сделать более фундаментальное открытие.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Разбор предложения"
      ],
      "metadata": {
        "id": "l0-NMKkH6wt7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spacy**"
      ],
      "metadata": {
        "id": "6GLpWaZvwesW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy"
      ],
      "metadata": {
        "id": "EQjYJFSswnBC"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(spacy_test, style='dep', jupyter=True)"
      ],
      "metadata": {
        "id": "hoD3K9j-64z5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "b0744744-0199-41bc-a507-e7153d731d29"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"1db3aff146c04142ad31ef2d013f04bb-0\" class=\"displacy\" width=\"8625\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Ранним</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">майским</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">утром</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">к</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">гостинице «</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Дубки»</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">подкатил</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">светло-</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">серый</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">автомобиль.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">Распахнулась</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">дверца,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">из</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">машины</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">выскочил</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">человек</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">с</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">трубкой</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">в</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">зубах.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">Увидев</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">приветливые</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">лица,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">букеты</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\">цветов,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4425\">он</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4425\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4600\">смущённо</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4600\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4775\">улыбнулся.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4775\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4950\">Это</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4950\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5125\">был</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5125\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5300\">профессор</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5300\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5475\">Громов.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5475\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5650\">Почётный</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5650\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5825\">гость</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5825\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6000\">конгресса</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6000\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6175\">кибернетиков</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6175\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6350\">приехал</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6350\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6525\">из</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6525\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6700\">Синегорска,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6700\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6875\">сибирского</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6875\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7050\">научного</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7050\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7225\">городка,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7225\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7400\">и,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7400\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7575\">как</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7575\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7750\">всегда,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7750\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7925\">решил</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7925\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"8100\">остановиться</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"8100\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"8275\">в «</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"8275\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"8450\">Дубках».</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"8450\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-0\" stroke-width=\"2px\" d=\"M70,439.5 C70,264.5 385.0,264.5 385.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,441.5 L62,429.5 78,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-1\" stroke-width=\"2px\" d=\"M245,439.5 C245,352.0 380.0,352.0 380.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,441.5 L237,429.5 253,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-2\" stroke-width=\"2px\" d=\"M595,439.5 C595,352.0 730.0,352.0 730.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,441.5 L587,429.5 603,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-3\" stroke-width=\"2px\" d=\"M420,439.5 C420,264.5 735.0,264.5 735.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M735.0,441.5 L743.0,429.5 727.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-4\" stroke-width=\"2px\" d=\"M945,439.5 C945,352.0 1080.0,352.0 1080.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,441.5 L937,429.5 953,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-5\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,352.0 1430.0,352.0 1430.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,441.5 L1287,429.5 1303,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-6\" stroke-width=\"2px\" d=\"M1470,439.5 C1470,352.0 1605.0,352.0 1605.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1470,441.5 L1462,429.5 1478,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-7\" stroke-width=\"2px\" d=\"M1120,439.5 C1120,177.0 1615.0,177.0 1615.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1615.0,441.5 L1623.0,429.5 1607.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-8\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,352.0 1955.0,352.0 1955.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1820,441.5 L1812,429.5 1828,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-9\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,352.0 2305.0,352.0 2305.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2170,441.5 L2162,429.5 2178,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-10\" stroke-width=\"2px\" d=\"M2345,439.5 C2345,264.5 2660.0,264.5 2660.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2345,441.5 L2337,429.5 2353,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-11\" stroke-width=\"2px\" d=\"M2520,439.5 C2520,352.0 2655.0,352.0 2655.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2520,441.5 L2512,429.5 2528,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-12\" stroke-width=\"2px\" d=\"M2695,439.5 C2695,264.5 3010.0,264.5 3010.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2695,441.5 L2687,429.5 2703,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-13\" stroke-width=\"2px\" d=\"M2870,439.5 C2870,352.0 3005.0,352.0 3005.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2870,441.5 L2862,429.5 2878,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-14\" stroke-width=\"2px\" d=\"M1995,439.5 C1995,89.5 3020.0,89.5 3020.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3020.0,441.5 L3028.0,429.5 3012.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-15\" stroke-width=\"2px\" d=\"M3220,439.5 C3220,352.0 3355.0,352.0 3355.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3220,441.5 L3212,429.5 3228,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-16\" stroke-width=\"2px\" d=\"M1995,439.5 C1995,2.0 3375.0,2.0 3375.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3375.0,441.5 L3383.0,429.5 3367.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-17\" stroke-width=\"2px\" d=\"M3570,439.5 C3570,264.5 3885.0,264.5 3885.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3570,441.5 L3562,429.5 3578,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-18\" stroke-width=\"2px\" d=\"M3745,439.5 C3745,352.0 3880.0,352.0 3880.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3745,441.5 L3737,429.5 3753,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-19\" stroke-width=\"2px\" d=\"M3920,439.5 C3920,177.0 4415.0,177.0 4415.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3920,441.5 L3912,429.5 3928,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-20\" stroke-width=\"2px\" d=\"M4095,439.5 C4095,352.0 4230.0,352.0 4230.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4095,441.5 L4087,429.5 4103,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-21\" stroke-width=\"2px\" d=\"M3920,439.5 C3920,264.5 4235.0,264.5 4235.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4235.0,441.5 L4243.0,429.5 4227.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-22\" stroke-width=\"2px\" d=\"M4620,439.5 C4620,352.0 4755.0,352.0 4755.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4620,441.5 L4612,429.5 4628,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-23\" stroke-width=\"2px\" d=\"M4445,439.5 C4445,264.5 4760.0,264.5 4760.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4760.0,441.5 L4768.0,429.5 4752.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-24\" stroke-width=\"2px\" d=\"M4970,439.5 C4970,352.0 5105.0,352.0 5105.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4970,441.5 L4962,429.5 4978,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-25\" stroke-width=\"2px\" d=\"M5145,439.5 C5145,352.0 5280.0,352.0 5280.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-25\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5145,441.5 L5137,429.5 5153,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-26\" stroke-width=\"2px\" d=\"M5320,439.5 C5320,352.0 5455.0,352.0 5455.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-26\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5455.0,441.5 L5463.0,429.5 5447.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-27\" stroke-width=\"2px\" d=\"M5670,439.5 C5670,177.0 6165.0,177.0 6165.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-27\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5670,441.5 L5662,429.5 5678,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-28\" stroke-width=\"2px\" d=\"M5845,439.5 C5845,264.5 6160.0,264.5 6160.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-28\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5845,441.5 L5837,429.5 5853,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-29\" stroke-width=\"2px\" d=\"M6020,439.5 C6020,352.0 6155.0,352.0 6155.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-29\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6020,441.5 L6012,429.5 6028,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-30\" stroke-width=\"2px\" d=\"M6195,439.5 C6195,177.0 6690.0,177.0 6690.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-30\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6195,441.5 L6187,429.5 6203,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-31\" stroke-width=\"2px\" d=\"M6370,439.5 C6370,264.5 6685.0,264.5 6685.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-31\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6370,441.5 L6362,429.5 6378,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-32\" stroke-width=\"2px\" d=\"M6545,439.5 C6545,352.0 6680.0,352.0 6680.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-32\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6545,441.5 L6537,429.5 6553,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-33\" stroke-width=\"2px\" d=\"M6895,439.5 C6895,264.5 7210.0,264.5 7210.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-33\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6895,441.5 L6887,429.5 6903,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-34\" stroke-width=\"2px\" d=\"M7070,439.5 C7070,352.0 7205.0,352.0 7205.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-34\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M7070,441.5 L7062,429.5 7078,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-35\" stroke-width=\"2px\" d=\"M6720,439.5 C6720,177.0 7215.0,177.0 7215.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-35\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M7215.0,441.5 L7223.0,429.5 7207.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-36\" stroke-width=\"2px\" d=\"M7245,439.5 C7245,352.0 7380.0,352.0 7380.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-36\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M7380.0,441.5 L7388.0,429.5 7372.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-37\" stroke-width=\"2px\" d=\"M7595,439.5 C7595,352.0 7730.0,352.0 7730.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-37\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M7595,441.5 L7587,429.5 7603,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-38\" stroke-width=\"2px\" d=\"M6720,439.5 C6720,89.5 7745.0,89.5 7745.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-38\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M7745.0,441.5 L7753.0,429.5 7737.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-39\" stroke-width=\"2px\" d=\"M7945,439.5 C7945,352.0 8080.0,352.0 8080.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-39\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M7945,441.5 L7937,429.5 7953,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-40\" stroke-width=\"2px\" d=\"M8295,439.5 C8295,352.0 8430.0,352.0 8430.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-40\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M8295,441.5 L8287,429.5 8303,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1db3aff146c04142ad31ef2d013f04bb-0-41\" stroke-width=\"2px\" d=\"M8120,439.5 C8120,264.5 8435.0,264.5 8435.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1db3aff146c04142ad31ef2d013f04bb-0-41\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M8435.0,441.5 L8443.0,429.5 8427.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spacy.explain(\"NOUN\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2lRZT0dw2I4",
        "outputId": "8fb765b4-2234-426c-f16e-ea124e63024c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spacy.explain(\"amod\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSU_3-oYw2q_",
        "outputId": "6d618211-356a-4937-d4ed-0ad0d8dc1efc"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adjectival modifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Natasha**"
      ],
      "metadata": {
        "id": "Dugy2uyDwgjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from natasha import NewsSyntaxParser"
      ],
      "metadata": {
        "id": "FNu8VYImUBDk"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = NewsEmbedding()\n",
        "syntax_parser = NewsSyntaxParser(emb)"
      ],
      "metadata": {
        "id": "qXalehZMUB0b"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_doc.parse_syntax(syntax_parser)\n",
        "n_doc.sents[0].syntax.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmYR0kU3UDj1",
        "outputId": "e530d2de-289b-4d7d-e2a3-62a9c47cf07d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ┌──► Эти         det\n",
            "    │ ┌► змееволосые amod\n",
            "  ┌►└─└─ дамочки     nsubj\n",
            "  │   ┌► уже         advmod\n",
            "┌─└─┌─└─ начали      \n",
            "│   └►┌─ раздражать  xcomp\n",
            "│     └► Перси       obj\n",
            "└──────► .           punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_doc.parse_syntax(syntax_parser)\n",
        "n_doc.sents[1].syntax.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDGZC_59UJA6",
        "outputId": "e516d750-acbc-42d7-c7bc-07993be6acb5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          ┌► Они          nsubj\n",
            "┌─────┌─┌─└─ должны       \n",
            "│     │ └──► были         cop\n",
            "│ ┌─┌─└────► умереть      xcomp\n",
            "│ │ │   ┌──► еще          advmod\n",
            "│ │ │   │ ┌► три          nummod:gov\n",
            "│ │ └──►└─└─ дня          obl\n",
            "│ │     └──► назад        advmod\n",
            "│ │   ┌────► ,            punct\n",
            "│ │   │ ┌──► когда        mark\n",
            "│ │   │ │ ┌► он           nsubj\n",
            "│ └►┌─└─└─└─ сбросил      advcl\n",
            "│   │ │   ┌► на           case\n",
            "│   │ └──►└─ них          obl\n",
            "│   └──►┌─── ящик         obj\n",
            "│       │ ┌► с            case\n",
            "│     ┌─└►└─ шарами       nmod\n",
            "│     │   ┌► для          case\n",
            "│ ┌─┌─└──►└─ боулинга     nmod\n",
            "│ │ │   ┌──► в            case\n",
            "│ │ │   │ ┌► «            punct\n",
            "│ │ └──►└─└─ Баргин-Марте nmod\n",
            "│ │     └──► »            punct\n",
            "│ │       ┌► в            case\n",
            "│ └──────►└─ Напе         nmod\n",
            "└──────────► .            punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_doc.parse_syntax(syntax_parser)\n",
        "n_doc.sents[2].syntax.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lNMWNw5UJfZ",
        "outputId": "fac78ebf-348d-4069-eaa5-63eee316de97"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            ┌► Они         nsubj\n",
            "┌───┌───┌─┌─└─ должны      \n",
            "│   │   │ └──► были        cop\n",
            "│ ┌─│   └──►┌─ отдать      xcomp\n",
            "│ │ │       └► концы       obj\n",
            "│ │ │       ┌► два         nummod:gov\n",
            "│ │ │ ┌──►┌─└─ дня         obl\n",
            "│ │ │ │   └──► назад       advmod\n",
            "│ │ │ │   ┌──► ,           punct\n",
            "│ │ │ │   │ ┌► после       case\n",
            "│ │ └►│ ┌─└─└─ того        obl\n",
            "│ │   │ │ ┌──► как         mark\n",
            "│ │   │ │ │ ┌► он          nsubj\n",
            "│ │   └─└►└─└─ переехал    acl\n",
            "│ │       ┌──► их          det\n",
            "│ │       │ ┌► полицейским amod\n",
            "│ └────►┌─└─└─ автомобилем iobj\n",
            "│       │   ┌► в           case\n",
            "│       └──►└─ Мартинесе   nmod\n",
            "└────────────► .           punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_doc2.parse_syntax(syntax_parser)\n",
        "n_doc2.sents[0].syntax.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW_vyRu4UQue",
        "outputId": "44276a76-0031-4250-a20c-1f2a81136e33"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            ┌► Сам           amod\n",
            "        ┌►┌─└─ факт          nsubj\n",
            "        │ └──► Посещения     nmod\n",
            "┌───┌─┌─└───── является      \n",
            "│   │ │     ┌► наиболее      advmod\n",
            "│   │ │   ┌►└─ важным        amod\n",
            "│ ┌─│ └──►└─── открытием     xcomp\n",
            "│ │ │ ┌────►┌─ не            cc\n",
            "│ │ │ │     └► только        fixed\n",
            "│ │ │ │ ┌────► за            case\n",
            "│ │ │ │ │ ┌──► истекшие      amod\n",
            "│ │ │ │ │ │ ┌► тринадцать    nummod:gov\n",
            "│ │ └►└─└─└─└─ лет           obl\n",
            "│ │   ┌──────► ,             punct\n",
            "│ │   │ ┌──►┌─ но            cc\n",
            "│ │   │ │   └► и             fixed\n",
            "│ │   │ │ ┌──► за            case\n",
            "│ │   │ │ │ ┌► все           det\n",
            "│ └──►└─└─└─└─ время         nmod\n",
            "│         └►┌─ существования nmod\n",
            "│           └► человечества  nmod\n",
            "└────────────► .             punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Решение задачи классификации текста"
      ],
      "metadata": {
        "id": "0s2nPDA667h3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подключение библиотек\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, Tuple\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score \n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline \n",
        "sns.set(style=\"ticks\")"
      ],
      "metadata": {
        "id": "IsER1seMUV7V"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Способ 1. Векторизация текста на основе модели \"мешка слов\""
      ],
      "metadata": {
        "id": "nmJGqBvV7GEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = [\"rec.motorcycles\", \"rec.sport.baseball\", \"sci.electronics\",\"sci.med\"]\n",
        "newsgroups = fetch_20newsgroups(subset='train', categories=categories)\n",
        "data = newsgroups['data']"
      ],
      "metadata": {
        "id": "zKkabKZ7z1x6"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray) -> Dict[int, float]:\n",
        "    \"\"\"\n",
        "    Вычисление метрики accuracy для каждого класса\n",
        "    y_true - истинные значения классов\n",
        "    y_pred - предсказанные значения классов\n",
        "    Возвращает словарь: ключ - метка класса, \n",
        "    значение - Accuracy для данного класса\n",
        "    \"\"\"\n",
        "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
        "    d = {'t': y_true, 'p': y_pred}\n",
        "    df = pd.DataFrame(data=d)\n",
        "    # Метки классов\n",
        "    classes = np.unique(y_true)\n",
        "    # Результирующий словарь\n",
        "    res = dict()\n",
        "    # Перебор меток классов\n",
        "    for c in classes:\n",
        "        # отфильтруем данные, которые соответствуют \n",
        "        # текущей метке класса в истинных значениях\n",
        "        temp_data_flt = df[df['t']==c]\n",
        "        # расчет accuracy для заданной метки класса\n",
        "        temp_acc = accuracy_score(\n",
        "            temp_data_flt['t'].values, \n",
        "            temp_data_flt['p'].values)\n",
        "        # сохранение результата в словарь\n",
        "        res[c] = temp_acc\n",
        "    return res\n",
        "\n",
        "def print_accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray):\n",
        "    \"\"\"\n",
        "    Вывод метрики accuracy для каждого класса\n",
        "    \"\"\"\n",
        "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
        "    if len(accs)>0:\n",
        "        print('Метка \\t Accuracy')\n",
        "    for i in accs:\n",
        "        print('{} \\t {}'.format(i, accs[i]))"
      ],
      "metadata": {
        "id": "iNoccxXdz7I7"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabVect = CountVectorizer()\n",
        "vocabVect.fit(data)\n",
        "corpusVocab = vocabVect.vocabulary_\n",
        "print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"
      ],
      "metadata": {
        "id": "p4g8eaIq7JJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd58e547-9175-494e-dc06-2d25ab023e30"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество сформированных признаков - 33448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list(corpusVocab)[1:10]:\n",
        "    print('{}={}'.format(i, corpusVocab[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP9LOSVd0Hr6",
        "outputId": "ccb82fa9-160a-4d75-f284-2c86c1228f2d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nrmendel=22213\n",
            "unix=31462\n",
            "amherst=5287\n",
            "edu=12444\n",
            "nathaniel=21624\n",
            "mendell=20477\n",
            "subject=29220\n",
            "re=25369\n",
            "bike=6898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Использование класса CountVectorizer"
      ],
      "metadata": {
        "id": "-oehFFc_0Jxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_features = vocabVect.transform(data)\n",
        "test_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiDvLcMP0OdS",
        "outputId": "a7a650f5-49be-44e7-9e3a-8df1bdbeafea"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2380x33448 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 335176 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_features.todense()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c46IRFoM0PD2",
        "outputId": "2a5ed068-e3f8-4b7e-a86e-98e9eccec16b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [2, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Размер нулевой строки\n",
        "len(test_features.todense()[0].getA1())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFE1_bnw0QLn",
        "outputId": "b2e4b0ba-f677-40cb-8cab-d99b70668a7a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33448"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Непустые значения нулевой строки\n",
        "print([i for i in test_features.todense()[0].getA1() if i>0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4svP_Y90UUV",
        "outputId": "7c7d3a44-a123-47af-93da-730dd0a837fb"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabVect.get_feature_names()[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39bigzZS0WJh",
        "outputId": "175e7f7c-7397-4b08-f5c0-0e735b15d736"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00',\n",
              " '000',\n",
              " '0000',\n",
              " '0000000004',\n",
              " '0000000005',\n",
              " '0000000667',\n",
              " '0000001200',\n",
              " '0001',\n",
              " '00014',\n",
              " '0002']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Решение задачи анализа тональности текста на основе модели \"мешка слов\""
      ],
      "metadata": {
        "id": "XhsMJ-RI0bh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def VectorizeAndClassify(vectorizers_list, classifiers_list):\n",
        "    for v in vectorizers_list:\n",
        "        for c in classifiers_list:\n",
        "            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n",
        "            score = cross_val_score(pipeline1, newsgroups['data'], newsgroups['target'], scoring='accuracy', cv=3).mean()\n",
        "            print('Векторизация - {}'.format(v))\n",
        "            print('Модель для классификации - {}'.format(c))\n",
        "            print('Accuracy = {}'.format(score))\n",
        "            print('===========================')"
      ],
      "metadata": {
        "id": "dLvJ4qLP0fzK"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizers_list = [CountVectorizer(vocabulary = corpusVocab)]\n",
        "classifiers_list = [LogisticRegression(C=3.0), LinearSVC(), KNeighborsClassifier()]\n",
        "VectorizeAndClassify(vectorizers_list, classifiers_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIwIT0GN0jXZ",
        "outputId": "1a34494f-ca75-49fb-ce81-926697acaad6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n",
            "                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n",
            "                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n",
            "                            '0005111312': 11, '0005111312na1em': 12,\n",
            "                            '00072': 13, '000851': 14, '000rpm': 15,\n",
            "                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n",
            "                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n",
            "                            '001813': 24, '002': 25, '002222': 26,\n",
            "                            '002251w': 27, '0023': 28, '002937': 29, ...})\n",
            "Модель для классификации - LogisticRegression(C=3.0)\n",
            "Accuracy = 0.937813339432037\n",
            "===========================\n",
            "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n",
            "                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n",
            "                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n",
            "                            '0005111312': 11, '0005111312na1em': 12,\n",
            "                            '00072': 13, '000851': 14, '000rpm': 15,\n",
            "                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n",
            "                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n",
            "                            '001813': 24, '002': 25, '002222': 26,\n",
            "                            '002251w': 27, '0023': 28, '002937': 29, ...})\n",
            "Модель для классификации - LinearSVC()\n",
            "Accuracy = 0.9453742497059174\n",
            "===========================\n",
            "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n",
            "                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n",
            "                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n",
            "                            '0005111312': 11, '0005111312na1em': 12,\n",
            "                            '00072': 13, '000851': 14, '000rpm': 15,\n",
            "                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n",
            "                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n",
            "                            '001813': 24, '002': 25, '002222': 26,\n",
            "                            '002251w': 27, '0023': 28, '002937': 29, ...})\n",
            "Модель для классификации - KNeighborsClassifier()\n",
            "Accuracy = 0.6655358653541747\n",
            "===========================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Разделим выборку на обучающую и тестовую и проверим решение для лучшей модели"
      ],
      "metadata": {
        "id": "ZdQHu4i80m1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(newsgroups['data'], newsgroups['target'], test_size=0.5, random_state=1)"
      ],
      "metadata": {
        "id": "RCva3Dn00qmr"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment(v, c):\n",
        "    model = Pipeline(\n",
        "        [(\"vectorizer\", v), \n",
        "         (\"classifier\", c)])\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print_accuracy_score_for_classes(y_test, y_pred)"
      ],
      "metadata": {
        "id": "3OXeo6WY0tHC"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment(CountVectorizer(), LinearSVC())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxBlSZf10rnO",
        "outputId": "615ad2b8-6333-402d-ff0e-924b6bf1fb2a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метка \t Accuracy\n",
            "0 \t 0.9290322580645162\n",
            "1 \t 0.9675090252707581\n",
            "2 \t 0.9026845637583892\n",
            "3 \t 0.9245901639344263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Способ 2. Работа с векторными представлениями слов с использованием word2vec"
      ],
      "metadata": {
        "id": "KUTzDcml7SxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import word2vec"
      ],
      "metadata": {
        "id": "4iUhQZK87P_c"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zukmfaIYzQXU",
        "outputId": "13e5d7a8-f7dd-44a9-870f-b5178e94aa42"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (6.0.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, Tuple\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk import WordPunctTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "QEMPbEfg7Qgt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef2c5e7a-4658-4e24-eee2-0e92820ad1a5"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/ruscorpora_mystem_cbow_300_2_2015.bin.gz'"
      ],
      "metadata": {
        "id": "P8_lVGnGzW2b"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)"
      ],
      "metadata": {
        "id": "CCquN4PnzYiX"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['холод_S', 'мороз_S', 'береза_S', 'сосна_S']"
      ],
      "metadata": {
        "id": "Ob2o7nqvza8-"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    if word in model:\n",
        "        print('\\nСЛОВО - {}'.format(word))\n",
        "        print('5 ближайших соседей слова:')\n",
        "        for word, sim in model.most_similar(positive=[word], topn=5):\n",
        "            print('{} => {}'.format(word, sim))\n",
        "    else:\n",
        "        print('Слово \"{}\" не найдено в модели'.format(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH1vkqqYLKSz",
        "outputId": "2a9a7dba-6e96-42a8-b0ab-6fe211fcd721"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "СЛОВО - холод_S\n",
            "5 ближайших соседей слова:\n",
            "стужа_S => 0.7676383852958679\n",
            "сырость_S => 0.6338975429534912\n",
            "жара_S => 0.6089427471160889\n",
            "мороз_S => 0.5890367031097412\n",
            "озноб_S => 0.5776054859161377\n",
            "\n",
            "СЛОВО - мороз_S\n",
            "5 ближайших соседей слова:\n",
            "стужа_S => 0.6425479650497437\n",
            "морозец_S => 0.5947279930114746\n",
            "холод_S => 0.5890367031097412\n",
            "жара_S => 0.5522176623344421\n",
            "снегопад_S => 0.5083199143409729\n",
            "\n",
            "СЛОВО - береза_S\n",
            "5 ближайших соседей слова:\n",
            "сосна_S => 0.7943247556686401\n",
            "тополь_S => 0.7562226057052612\n",
            "дуб_S => 0.7440178394317627\n",
            "дерево_S => 0.7373415231704712\n",
            "клен_S => 0.7105200290679932\n",
            "\n",
            "СЛОВО - сосна_S\n",
            "5 ближайших соседей слова:\n",
            "береза_S => 0.7943247556686401\n",
            "дерево_S => 0.7581434845924377\n",
            "лиственница_S => 0.747814953327179\n",
            "дуб_S => 0.7412480711936951\n",
            "ель_S => 0.7363824248313904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Находим близость между словами и строим аналогии"
      ],
      "metadata": {
        "id": "7CAGq-izLPgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.similarity('сосна_S', 'береза_S'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJBfNzIILRcP",
        "outputId": "fe849fbd-96f0-496d-f596-d5751f0eac75"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7943247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.most_similar(positive=['холод_S', 'стужа_S'], negative=['мороз_S']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boueOfMzLXZL",
        "outputId": "5eeee99a-813c-4866-d251-230c97f5cb9b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('сырость_S', 0.5040211081504822), ('стылость_S', 0.46336129307746887), ('голод_S', 0.4604816436767578), ('зной_S', 0.45904627442359924), ('скука_S', 0.4489358067512512), ('жара_S', 0.44645121693611145), ('усталость_S', 0.4218570291996002), ('озноб_S', 0.41469818353652954), ('духота_S', 0.4099087715148926), ('неуют_S', 0.40298789739608765)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучим word2vec на наборе данных \"fetch_20newsgroups\""
      ],
      "metadata": {
        "id": "OqWfo1fVLaA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, Tuple\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk import WordPunctTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXuRnboRLchG",
        "outputId": "c561b57f-c9c1-4b53-a085-b44724292114"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = [\"rec.motorcycles\", \"rec.sport.baseball\", \"sci.electronics\",\"sci.med\"]\n",
        "newsgroups = fetch_20newsgroups(subset='train', categories=categories)\n",
        "data = newsgroups['data']"
      ],
      "metadata": {
        "id": "aMCXWxcsLe3-"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовим корпус\n",
        "corpus = []\n",
        "stop_words = stopwords.words('english')\n",
        "tok = WordPunctTokenizer()\n",
        "for line in newsgroups['data']:\n",
        "    line1 = line.strip().lower()\n",
        "    line1 = re.sub(\"[^a-zA-Z]\",\" \", line1)\n",
        "    text_tok = tok.tokenize(line1)\n",
        "    text_tok1 = [w for w in text_tok if not w in stop_words]\n",
        "    corpus.append(text_tok1)"
      ],
      "metadata": {
        "id": "SISZtThA7VTz"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[:5]"
      ],
      "metadata": {
        "id": "8VBjkNGC7Xzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887e0a79-9bbc-4314-f55e-223ca3298f5b"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['nrmendel',\n",
              "  'unix',\n",
              "  'amherst',\n",
              "  'edu',\n",
              "  'nathaniel',\n",
              "  'mendell',\n",
              "  'subject',\n",
              "  'bike',\n",
              "  'advice',\n",
              "  'organization',\n",
              "  'amherst',\n",
              "  'college',\n",
              "  'x',\n",
              "  'newsreader',\n",
              "  'tin',\n",
              "  'version',\n",
              "  'pl',\n",
              "  'lines',\n",
              "  'ummm',\n",
              "  'bikes',\n",
              "  'kx',\n",
              "  'suggest',\n",
              "  'look',\n",
              "  'zx',\n",
              "  'since',\n",
              "  'horsepower',\n",
              "  'whereas',\n",
              "  'might',\n",
              "  'bit',\n",
              "  'much',\n",
              "  'sincerely',\n",
              "  'nathaniel',\n",
              "  'zx',\n",
              "  'dod',\n",
              "  'ama'],\n",
              " ['grante',\n",
              "  'aquarius',\n",
              "  'rosemount',\n",
              "  'com',\n",
              "  'grant',\n",
              "  'edwards',\n",
              "  'subject',\n",
              "  'krillean',\n",
              "  'photography',\n",
              "  'reply',\n",
              "  'grante',\n",
              "  'aquarius',\n",
              "  'rosemount',\n",
              "  'com',\n",
              "  'grant',\n",
              "  'edwards',\n",
              "  'organization',\n",
              "  'rosemount',\n",
              "  'inc',\n",
              "  'lines',\n",
              "  'nntp',\n",
              "  'posting',\n",
              "  'host',\n",
              "  'aquarius',\n",
              "  'stgprao',\n",
              "  'st',\n",
              "  'unocal',\n",
              "  'com',\n",
              "  'richard',\n",
              "  'ottolini',\n",
              "  'writes',\n",
              "  'living',\n",
              "  'things',\n",
              "  'maintain',\n",
              "  'small',\n",
              "  'electric',\n",
              "  'fields',\n",
              "  'enhance',\n",
              "  'certain',\n",
              "  'chemical',\n",
              "  'reactions',\n",
              "  'promote',\n",
              "  'communication',\n",
              "  'states',\n",
              "  'cell',\n",
              "  'communicate',\n",
              "  'cells',\n",
              "  'nervous',\n",
              "  'system',\n",
              "  'specialized',\n",
              "  'example',\n",
              "  'perhaps',\n",
              "  'uses',\n",
              "  'true',\n",
              "  'electric',\n",
              "  'fields',\n",
              "  'change',\n",
              "  'location',\n",
              "  'time',\n",
              "  'large',\n",
              "  'organism',\n",
              "  'also',\n",
              "  'true',\n",
              "  'special',\n",
              "  'photographic',\n",
              "  'techniques',\n",
              "  'applying',\n",
              "  'external',\n",
              "  'fields',\n",
              "  'kirillian',\n",
              "  'photography',\n",
              "  'interact',\n",
              "  'fields',\n",
              "  'resistances',\n",
              "  'caused',\n",
              "  'fields',\n",
              "  'make',\n",
              "  'interesting',\n",
              "  'pictures',\n",
              "  'really',\n",
              "  'kirlian',\n",
              "  'photography',\n",
              "  'taking',\n",
              "  'pictures',\n",
              "  'corona',\n",
              "  'discharge',\n",
              "  'objects',\n",
              "  'animate',\n",
              "  'inanimate',\n",
              "  'fields',\n",
              "  'applied',\n",
              "  'objects',\n",
              "  'millions',\n",
              "  'times',\n",
              "  'larger',\n",
              "  'biologically',\n",
              "  'created',\n",
              "  'fields',\n",
              "  'want',\n",
              "  'record',\n",
              "  'biologically',\n",
              "  'created',\n",
              "  'electric',\n",
              "  'fields',\n",
              "  'got',\n",
              "  'use',\n",
              "  'low',\n",
              "  'noise',\n",
              "  'high',\n",
              "  'gain',\n",
              "  'sensors',\n",
              "  'typical',\n",
              "  'eegs',\n",
              "  'ekgs',\n",
              "  'kirlian',\n",
              "  'photography',\n",
              "  'phun',\n",
              "  'physics',\n",
              "  'type',\n",
              "  'stuff',\n",
              "  'right',\n",
              "  'soaking',\n",
              "  'chunks',\n",
              "  'extra',\n",
              "  'fine',\n",
              "  'steel',\n",
              "  'wool',\n",
              "  'liquid',\n",
              "  'oxygen',\n",
              "  'hitting',\n",
              "  'hammer',\n",
              "  'like',\n",
              "  'kirlean',\n",
              "  'setup',\n",
              "  'fun',\n",
              "  'possibly',\n",
              "  'dangerous',\n",
              "  'perhaps',\n",
              "  'pictures',\n",
              "  'diagonistic',\n",
              "  'disease',\n",
              "  'problems',\n",
              "  'organisms',\n",
              "  'better',\n",
              "  'understood',\n",
              "  'perhaps',\n",
              "  'probably',\n",
              "  'grant',\n",
              "  'edwards',\n",
              "  'yow',\n",
              "  'vote',\n",
              "  'rosemount',\n",
              "  'inc',\n",
              "  'well',\n",
              "  'tapered',\n",
              "  'half',\n",
              "  'cocked',\n",
              "  'ill',\n",
              "  'conceived',\n",
              "  'grante',\n",
              "  'aquarius',\n",
              "  'rosemount',\n",
              "  'com',\n",
              "  'tax',\n",
              "  'deferred'],\n",
              " ['liny',\n",
              "  'sun',\n",
              "  'scri',\n",
              "  'fsu',\n",
              "  'edu',\n",
              "  'nemo',\n",
              "  'subject',\n",
              "  'bates',\n",
              "  'method',\n",
              "  'myopia',\n",
              "  'reply',\n",
              "  'lin',\n",
              "  'ray',\n",
              "  'met',\n",
              "  'fsu',\n",
              "  'edu',\n",
              "  'distribution',\n",
              "  'na',\n",
              "  'organization',\n",
              "  'scri',\n",
              "  'florida',\n",
              "  'state',\n",
              "  'university',\n",
              "  'lines',\n",
              "  'bates',\n",
              "  'method',\n",
              "  'work',\n",
              "  'first',\n",
              "  'heard',\n",
              "  'newsgroup',\n",
              "  'several',\n",
              "  'years',\n",
              "  'ago',\n",
              "  'got',\n",
              "  'hold',\n",
              "  'book',\n",
              "  'improve',\n",
              "  'sight',\n",
              "  'simple',\n",
              "  'daily',\n",
              "  'drills',\n",
              "  'relaxation',\n",
              "  'margaret',\n",
              "  'corbett',\n",
              "  'authorized',\n",
              "  'instructor',\n",
              "  'bates',\n",
              "  'method',\n",
              "  'published',\n",
              "  'talks',\n",
              "  'vision',\n",
              "  'improvement',\n",
              "  'relaxation',\n",
              "  'exercise',\n",
              "  'study',\n",
              "  'whether',\n",
              "  'method',\n",
              "  'actually',\n",
              "  'works',\n",
              "  'works',\n",
              "  'actually',\n",
              "  'shortening',\n",
              "  'previously',\n",
              "  'elongated',\n",
              "  'eyeball',\n",
              "  'increasing',\n",
              "  'lens',\n",
              "  'ability',\n",
              "  'flatten',\n",
              "  'order',\n",
              "  'compensate',\n",
              "  'long',\n",
              "  'eyeball',\n",
              "  'since',\n",
              "  'myopia',\n",
              "  'result',\n",
              "  'eyeball',\n",
              "  'elongation',\n",
              "  'seems',\n",
              "  'logical',\n",
              "  'approach',\n",
              "  'correction',\n",
              "  'find',\n",
              "  'way',\n",
              "  'reverse',\n",
              "  'process',\n",
              "  'e',\n",
              "  'shorten',\n",
              "  'somehow',\n",
              "  'preferably',\n",
              "  'non',\n",
              "  'surgically',\n",
              "  'recent',\n",
              "  'studies',\n",
              "  'find',\n",
              "  'know',\n",
              "  'rk',\n",
              "  'works',\n",
              "  'changing',\n",
              "  'curvature',\n",
              "  'cornea',\n",
              "  'compensate',\n",
              "  'shape',\n",
              "  'eyeball',\n",
              "  'way',\n",
              "  'train',\n",
              "  'muscles',\n",
              "  'shorten',\n",
              "  'eyeball',\n",
              "  'back',\n",
              "  'correct',\n",
              "  'length',\n",
              "  'would',\n",
              "  'even',\n",
              "  'better',\n",
              "  'bates',\n",
              "  'idea',\n",
              "  'right',\n",
              "  'thanks',\n",
              "  'information'],\n",
              " ['mcovingt',\n",
              "  'aisun',\n",
              "  'ai',\n",
              "  'uga',\n",
              "  'edu',\n",
              "  'michael',\n",
              "  'covington',\n",
              "  'subject',\n",
              "  'buy',\n",
              "  'parts',\n",
              "  'time',\n",
              "  'nntp',\n",
              "  'posting',\n",
              "  'host',\n",
              "  'aisun',\n",
              "  'ai',\n",
              "  'uga',\n",
              "  'edu',\n",
              "  'organization',\n",
              "  'ai',\n",
              "  'programs',\n",
              "  'university',\n",
              "  'georgia',\n",
              "  'athens',\n",
              "  'lines',\n",
              "  'pricing',\n",
              "  'parts',\n",
              "  'reminds',\n",
              "  'something',\n",
              "  'chemist',\n",
              "  'said',\n",
              "  'gram',\n",
              "  'dye',\n",
              "  'costs',\n",
              "  'dollar',\n",
              "  'comes',\n",
              "  'liter',\n",
              "  'jar',\n",
              "  'also',\n",
              "  'costs',\n",
              "  'dollar',\n",
              "  'want',\n",
              "  'whole',\n",
              "  'barrel',\n",
              "  'also',\n",
              "  'costs',\n",
              "  'dollar',\n",
              "  'e',\n",
              "  'charge',\n",
              "  'almost',\n",
              "  'exclusively',\n",
              "  'packaging',\n",
              "  'delivering',\n",
              "  'chemical',\n",
              "  'particular',\n",
              "  'case',\n",
              "  'byproduct',\n",
              "  'cost',\n",
              "  'almost',\n",
              "  'nothing',\n",
              "  'intrinsically',\n",
              "  'michael',\n",
              "  'covington',\n",
              "  'associate',\n",
              "  'research',\n",
              "  'scientist',\n",
              "  'artificial',\n",
              "  'intelligence',\n",
              "  'programs',\n",
              "  'mcovingt',\n",
              "  'ai',\n",
              "  'uga',\n",
              "  'edu',\n",
              "  'university',\n",
              "  'georgia',\n",
              "  'phone',\n",
              "  'athens',\n",
              "  'georgia',\n",
              "  'u',\n",
              "  'amateur',\n",
              "  'radio',\n",
              "  'n',\n",
              "  'tmi'],\n",
              " ['tammy',\n",
              "  'vandenboom',\n",
              "  'launchpad',\n",
              "  'unc',\n",
              "  'edu',\n",
              "  'tammy',\n",
              "  'vandenboom',\n",
              "  'subject',\n",
              "  'sore',\n",
              "  'spot',\n",
              "  'testicles',\n",
              "  'nntp',\n",
              "  'posting',\n",
              "  'host',\n",
              "  'lambada',\n",
              "  'oit',\n",
              "  'unc',\n",
              "  'edu',\n",
              "  'organization',\n",
              "  'university',\n",
              "  'north',\n",
              "  'carolina',\n",
              "  'extended',\n",
              "  'bulletin',\n",
              "  'board',\n",
              "  'service',\n",
              "  'distribution',\n",
              "  'na',\n",
              "  'lines',\n",
              "  'husband',\n",
              "  'woke',\n",
              "  'three',\n",
              "  'days',\n",
              "  'ago',\n",
              "  'small',\n",
              "  'sore',\n",
              "  'spot',\n",
              "  'spot',\n",
              "  'size',\n",
              "  'nickel',\n",
              "  'one',\n",
              "  'testicles',\n",
              "  'bottom',\n",
              "  'side',\n",
              "  'knots',\n",
              "  'lumps',\n",
              "  'little',\n",
              "  'sore',\n",
              "  'spot',\n",
              "  'says',\n",
              "  'reminds',\n",
              "  'bruise',\n",
              "  'feels',\n",
              "  'recollection',\n",
              "  'hitting',\n",
              "  'anything',\n",
              "  'like',\n",
              "  'would',\n",
              "  'cause',\n",
              "  'bruise',\n",
              "  'asssures',\n",
              "  'remember',\n",
              "  'something',\n",
              "  'like',\n",
              "  'clues',\n",
              "  'might',\n",
              "  'somewhat',\n",
              "  'hypochondriac',\n",
              "  'sp',\n",
              "  'sure',\n",
              "  'gonna',\n",
              "  'die',\n",
              "  'thanks',\n",
              "  'opinions',\n",
              "  'expressed',\n",
              "  'necessarily',\n",
              "  'university',\n",
              "  'north',\n",
              "  'carolina',\n",
              "  'chapel',\n",
              "  'hill',\n",
              "  'campus',\n",
              "  'office',\n",
              "  'information',\n",
              "  'technology',\n",
              "  'experimental',\n",
              "  'bulletin',\n",
              "  'board',\n",
              "  'service',\n",
              "  'internet',\n",
              "  'launchpad',\n",
              "  'unc',\n",
              "  'edu']]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time model_dz = word2vec.Word2Vec(corpus, workers=4, min_count=10, window=10, sample=1e-3)"
      ],
      "metadata": {
        "id": "g_gIEENn7Y5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a77f1e4-cab6-4c59-986b-4042c50131a9"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.68 s, sys: 66 ms, total: 4.75 s\n",
            "Wall time: 2.98 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверим, что модель обучилась\n",
        "print(model_dz.wv.most_similar(positive=['find'], topn=5))"
      ],
      "metadata": {
        "id": "wlix9xok7YwG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f570db-c138-45a2-d390-faba86f8a6ce"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('circuit', 0.9914703369140625), ('voltage', 0.9902374744415283), ('using', 0.9898467063903809), ('impedance', 0.9878386855125427), ('etc', 0.9866609573364258)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment(v, c):\n",
        "    model = Pipeline(\n",
        "        [(\"vectorizer\", v), \n",
        "         (\"classifier\", c)])\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print_accuracy_score_for_classes(y_test, y_pred)"
      ],
      "metadata": {
        "id": "ix2AkQK-7hEo"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Проверка качества работы модели word2vec"
      ],
      "metadata": {
        "id": "sv_8DZDUMC86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingVectorizer(object):\n",
        "    '''\n",
        "    Для текста усредним вектора входящих в него слов\n",
        "    '''\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.size = model.vector_size\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([np.mean(\n",
        "            [self.model[w] for w in words if w in self.model] \n",
        "            or [np.zeros(self.size)], axis=0)\n",
        "            for words in X])\n",
        "def accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray) -> Dict[int, float]:\n",
        "    \"\"\"\n",
        "    Вычисление метрики accuracy для каждого класса\n",
        "    y_true - истинные значения классов\n",
        "    y_pred - предсказанные значения классов\n",
        "    Возвращает словарь: ключ - метка класса, \n",
        "    значение - Accuracy для данного класса\n",
        "    \"\"\"\n",
        "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
        "    d = {'t': y_true, 'p': y_pred}\n",
        "    df = pd.DataFrame(data=d)\n",
        "    # Метки классов\n",
        "    classes = np.unique(y_true)\n",
        "    # Результирующий словарь\n",
        "    res = dict()\n",
        "    # Перебор меток классов\n",
        "    for c in classes:\n",
        "        # отфильтруем данные, которые соответствуют \n",
        "        # текущей метке класса в истинных значениях\n",
        "        temp_data_flt = df[df['t']==c]\n",
        "        # расчет accuracy для заданной метки класса\n",
        "        temp_acc = accuracy_score(\n",
        "            temp_data_flt['t'].values, \n",
        "            temp_data_flt['p'].values)\n",
        "        # сохранение результата в словарь\n",
        "        res[c] = temp_acc\n",
        "    return res\n",
        "\n",
        "def print_accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray):\n",
        "    \"\"\"\n",
        "    Вывод метрики accuracy для каждого класса\n",
        "    \"\"\"\n",
        "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
        "    if len(accs)>0:\n",
        "        print('Метка \\t Accuracy')\n",
        "    for i in accs:\n",
        "        print('{} \\t {}'.format(i, accs[i]))"
      ],
      "metadata": {
        "id": "bHykJZqQ7mcF"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучающая и тестовая выборки\n",
        "boundary = 1000\n",
        "X_train = corpus[:boundary] \n",
        "X_test = corpus[boundary:]\n",
        "y_train = newsgroups['target'][:boundary]\n",
        "y_test = newsgroups['target'][boundary:]"
      ],
      "metadata": {
        "id": "ahnn5qX57wpa"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "sentiment(EmbeddingVectorizer(model_dz.wv), LogisticRegression(C=5.0))"
      ],
      "metadata": {
        "id": "eQeebgTr7xVE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4aaa49-db2d-4b71-c988-7c05c3eade09"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метка \t Accuracy\n",
            "0 \t 0.8233618233618234\n",
            "1 \t 0.9015384615384615\n",
            "2 \t 0.736231884057971\n",
            "3 \t 0.7214484679665738\n",
            "CPU times: user 798 ms, sys: 205 ms, total: 1 s\n",
            "Wall time: 754 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результаты:  \n",
        "Модель CountVectorizer\n",
        "\n",
        "```\n",
        "Метка \t Accuracy\n",
        "0 \t 0.9290322580645162\n",
        "1 \t 0.9675090252707581\n",
        "2 \t 0.9026845637583892\n",
        "3 \t 0.9245901639344263\n",
        "```\n",
        "Модель word2vec\n",
        "\n",
        "```\n",
        "Метка \t Accuracy\n",
        "0 \t 0.8233618233618234\n",
        "1 \t 0.9015384615384615\n",
        "2 \t 0.736231884057971\n",
        "3 \t 0.7214484679665738\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a4LqmUdaQdeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Выводы\n",
        "Как видно из результатов проверки качества моделей, лучшее качество показал CountVectorizer.  \n",
        "Результаты, полученные с помощью word2vec не очень хоршие, скорее всего здесь нестандартность лексики ещё больше влияет на работу уже предобученной на более-менее формальных корпусах модели. Короткие неформальные сообщения скорее всего требуют немного других подходов."
      ],
      "metadata": {
        "id": "6KYq35TT71ol"
      }
    }
  ]
}