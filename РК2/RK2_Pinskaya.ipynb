{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RK2_Pinskaya.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PinskayaNika/MMO_Pinskaya/blob/main/%D0%A0%D0%9A2/RK2_Pinskaya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Рубежный контроль №2**\n",
        "**Студент:** Пинская Ника Марковна  \n",
        "**Группа:** ИУ5-21М   \n",
        "**Вариант (номер по списку группы):** 9  \n",
        "**Тема:** Методы обработки текстов \n",
        "\n",
        "**Решение задачи классификации текстов**  \n",
        "\n",
        "Необходимо решить задачу классификации текстов на основе любого выбранного Вами датасета (кроме примера, который рассматривался в лекции). Классификация может быть бинарной или многоклассовой. Целевой признак из выбранного Вами датасета может иметь любой физический смысл, примером является задача анализа тональности текста.\n",
        "\n",
        "Необходимо сформировать два варианта векторизации признаков - на основе CountVectorizer и на основе TfidfVectorizer.\n",
        "\n",
        "В качестве классификаторов необходимо использовать два классификатора по варианту для группы ИУ5-21М:\n",
        "\n",
        "**Классификатор №1:** LogisticRegression  \n",
        "**Классификатор №2:** Multinomial Naive Bayes - MNB"
      ],
      "metadata": {
        "id": "VTIqKb-C4h8T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0wwlAaPqsEiN"
      },
      "outputs": [],
      "source": [
        "#Импорт библиотек\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, Tuple\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score \n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#from sklearn.datasets import fetch_20newsgroups\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline \n",
        "sns.set(style=\"ticks\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подключение к gogle диску\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J91bS6jYhGjw",
        "outputId": "14471563-e784-40f3-edf3-64be3eed11d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Вывод содержимого папки на диске\n",
        "import os\n",
        "data_root = '/content/drive/MyDrive/MMO'\n",
        "print(os.listdir(data_root))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGBYrp7uhPaR",
        "outputId": "548bd746-1956-4271-eef1-c91eda27f6d3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pulitzer-circulation-data.csv', 'mmsa-icu-beds2.csv', 'movies.csv.zip', 'movies2.csv.zip', 'movies1.csv.zip', 'avengers.csv.zip', 'comma-survey.csv.zip', 'Tweets.csv.zip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Распаковка архива с датасетом\n",
        "!unzip /content/drive/MyDrive/MMO/Tweets.csv.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrufCaU7dee-",
        "outputId": "631550d4-9cbc-48ed-d46f-a5aa762082e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/MMO/Tweets.csv.zip\n",
            "replace Tweets.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: Tweets.csv              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных\n",
        "data = pd.read_csv(\"Tweets.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "yy8o2WhNW_N8",
        "outputId": "ba9a84fb-5628-4bc9-fe04-465ce0bd94f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
              "0  570306133677760513           neutral                        1.0000   \n",
              "1  570301130888122368          positive                        0.3486   \n",
              "2  570301083672813571           neutral                        0.6837   \n",
              "3  570301031407624196          negative                        1.0000   \n",
              "4  570300817074462722          negative                        1.0000   \n",
              "\n",
              "  negativereason  negativereason_confidence         airline  \\\n",
              "0            NaN                        NaN  Virgin America   \n",
              "1            NaN                     0.0000  Virgin America   \n",
              "2            NaN                        NaN  Virgin America   \n",
              "3     Bad Flight                     0.7033  Virgin America   \n",
              "4     Can't Tell                     1.0000  Virgin America   \n",
              "\n",
              "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
              "0                    NaN     cairdin                 NaN              0   \n",
              "1                    NaN    jnardino                 NaN              0   \n",
              "2                    NaN  yvonnalynn                 NaN              0   \n",
              "3                    NaN    jnardino                 NaN              0   \n",
              "4                    NaN    jnardino                 NaN              0   \n",
              "\n",
              "                                                text tweet_coord  \\\n",
              "0                @VirginAmerica What @dhepburn said.         NaN   \n",
              "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
              "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
              "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
              "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
              "\n",
              "               tweet_created tweet_location               user_timezone  \n",
              "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
              "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
              "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
              "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
              "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d48040d-007d-4ff0-95ae-aacbbdd30741\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d48040d-007d-4ff0-95ae-aacbbdd30741')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d48040d-007d-4ff0-95ae-aacbbdd30741 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d48040d-007d-4ff0-95ae-aacbbdd30741');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW4ckCLsXDPI",
        "outputId": "3f9452b4-0269-4983-9971-aab253d36bc2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data = data.overview.fillna(' ')"
      ],
      "metadata": {
        "id": "ySnFRsRErxrR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сформируем общий словарь для обучения моделей из обучающей и тестовой выборки\n",
        "vocab_list = data['name'].tolist()\n",
        "vocab_list[1:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3p7p5KFXFTc",
        "outputId": "25c2bc71-0d63-49d2-880f-7119a60c4ea1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jnardino',\n",
              " 'yvonnalynn',\n",
              " 'jnardino',\n",
              " 'jnardino',\n",
              " 'jnardino',\n",
              " 'cjmcginnis',\n",
              " 'pilot',\n",
              " 'dhepburn',\n",
              " 'YupitsTate']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabVect = CountVectorizer()\n",
        "vocabVect.fit(vocab_list)\n",
        "corpusVocab = vocabVect.vocabulary_\n",
        "print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78lL0eC6XMr_",
        "outputId": "643435cc-4a44-4a1a-fdc7-be3702a561ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество сформированных признаков - 7704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list(corpusVocab)[1:10]:\n",
        "    print('{}={}'.format(i, corpusVocab[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfaZA-qgXNUL",
        "outputId": "63b2c07f-9f75-4255-8838-e3830073d830"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jnardino=3479\n",
            "yvonnalynn=7668\n",
            "cjmcginnis=1391\n",
            "pilot=5660\n",
            "dhepburn=1873\n",
            "yupitstate=7667\n",
            "idk_but_youtube=2980\n",
            "hypercamilax=2941\n",
            "mollanderson=5011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# categories = [\"rec.motorcycles\", \"rec.sport.baseball\", \"sci.electronics\",\"sci.med\"]\n",
        "# newsgroups = fetch_20newsgroups(subset='train', categories=categories)\n",
        "# data = newsgroups['data']"
      ],
      "metadata": {
        "id": "R0Y8D2Z87ru0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray) -> Dict[int, float]:\n",
        "    \"\"\"\n",
        "    Вычисление метрики accuracy для каждого класса\n",
        "    y_true - истинные значения классов\n",
        "    y_pred - предсказанные значения классов\n",
        "    Возвращает словарь: ключ - метка класса, \n",
        "    значение - Accuracy для данного класса\n",
        "    \"\"\"\n",
        "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
        "    d = {'t': y_true, 'p': y_pred}\n",
        "    df = pd.DataFrame(data=d)\n",
        "    # Метки классов\n",
        "    classes = np.unique(y_true)\n",
        "    # Результирующий словарь\n",
        "    res = dict()\n",
        "    # Перебор меток классов\n",
        "    for c in classes:\n",
        "        # отфильтруем данные, которые соответствуют \n",
        "        # текущей метке класса в истинных значениях\n",
        "        temp_data_flt = df[df['t']==c]\n",
        "        # расчет accuracy для заданной метки класса\n",
        "        temp_acc = accuracy_score(\n",
        "            temp_data_flt['t'].values, \n",
        "            temp_data_flt['p'].values)\n",
        "        # сохранение результата в словарь\n",
        "        res[c] = temp_acc\n",
        "    return res\n",
        "\n",
        "def print_accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray):\n",
        "    \"\"\"\n",
        "    Вывод метрики accuracy для каждого класса\n",
        "    \"\"\"\n",
        "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
        "    if len(accs)>0:\n",
        "        print('Метка \\t Accuracy')\n",
        "    for i in accs:\n",
        "        print('{} \\t {}'.format(i, accs[i]))"
      ],
      "metadata": {
        "id": "lN1_cwzS7uKg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x = data.overview.fillna(' ')\n",
        "# vocabVect = CountVectorizer()\n",
        "# vocabVect.fit(data[x])\n",
        "# corpusVocab = vocabVect.vocabulary_\n",
        "# print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"
      ],
      "metadata": {
        "id": "CtMgNQnj7yUX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in list(corpusVocab)[1:10]:\n",
        "#     print('{}={}'.format(i, corpusVocab[i]))"
      ],
      "metadata": {
        "id": "xfEa8EqH7zEv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Использование класса *CountVectorizer***  \n",
        "Подсчитывает количество слов словаря, входящих в данный текст."
      ],
      "metadata": {
        "id": "LSC8nGhzTi4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_features = vocabVect.transform(data)\n",
        "test_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnSDF58570pM",
        "outputId": "9a70f6c3-ac2a-42d2-83dc-d901ba98b030"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<15x7704 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 0 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_features.todense()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqUw5Jw1UhXh",
        "outputId": "d33b9352-b48c-4c4b-ee10-b485c0c3ef29"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Размер нулевой строки\n",
        "len(test_features.todense()[0].getA1())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyk6ryzl730s",
        "outputId": "7fa2569d-cc83-48ef-c43e-fa0f19018358"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7704"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Непустые значения нулевой строки\n",
        "[i for i in test_features.todense()[0].getA1() if i>0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGP-H0a1Upwh",
        "outputId": "39af18c8-3826-4d63-ed36-64f6a19cf333"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabVect.get_feature_names()[100:120]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgOtWBY374iE",
        "outputId": "32780015-c517-4aa4-fe36-ad3cac5829f9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_mulazoe',\n",
              " '_paulinha9',\n",
              " '_raulll',\n",
              " '_robprice',\n",
              " '_rtuck',\n",
              " '_samanthaakira',\n",
              " '_saranguyen',\n",
              " '_stephanieejayy',\n",
              " '_therobynshow',\n",
              " '_troyjohnson',\n",
              " '_yohoka_',\n",
              " 'a_a_ron_cbus',\n",
              " 'a_for_adnauseam',\n",
              " 'a_geechi',\n",
              " 'a_lichtenfels',\n",
              " 'a_panfalone',\n",
              " 'aakopel',\n",
              " 'aaron_lawlor',\n",
              " 'aaronaebie',\n",
              " 'aarongirson']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Использование класса *TfidfVectorizer***  \n",
        "Вычисляет специфичность текста в корпусе текстов на основе метрики *TF-IDF*."
      ],
      "metadata": {
        "id": "hWuNR9oEVQvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfv = TfidfVectorizer(ngram_range=(1,3))\n",
        "tfidf_ngram_features = tfidfv.fit_transform(vocab_list)\n",
        "# tfidf_ngram_features = tfidfv.fit_transform(data['overview'])\n",
        "tfidf_ngram_features"
      ],
      "metadata": {
        "id": "bNGiQ3S6Vqd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847d1ef0-96af-4e91-8c2f-c8a5c7e716e2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<14640x7707 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 14654 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_ngram_features.todense()"
      ],
      "metadata": {
        "id": "OAgRiKT8VtQK",
        "outputId": "6cda2602-c41a-4306-d02e-517305cc86bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Размер нулевой строки\n",
        "len(tfidf_ngram_features.todense()[0].getA1())"
      ],
      "metadata": {
        "id": "sR4IoY-6VzeJ",
        "outputId": "f84cf801-582f-4009-e47a-e1c21508579e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7707"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Непустые значения нулевой строки\n",
        "[i for i in tfidf_ngram_features.todense()[0].getA1() if i>0]"
      ],
      "metadata": {
        "id": "nXb8UabyV0p4",
        "outputId": "87f493f6-5974-4031-974e-5351ee9187ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Решение задачи анализа тональности текста**  \n",
        "С использованием кросс-валидации попробуем применить к корпусу текстов различные варианты векторизации и классификации."
      ],
      "metadata": {
        "id": "vEfcxz7SWCuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных\n",
        "data2 = pd.read_csv(\"/content/drive/MyDrive/MMO/pulitzer-circulation-data.csv\")\n",
        "data2.head()"
      ],
      "metadata": {
        "id": "4n6X2XBS7zZs",
        "outputId": "a20d0079-8968-456e-b052-60afde195e8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Newspaper Daily Circulation, 2004 Daily Circulation, 2013  \\\n",
              "0            USA Today               2,192,098               1,674,306   \n",
              "1  Wall Street Journal               2,101,017               2,378,827   \n",
              "2       New York Times               1,119,027               1,865,318   \n",
              "3    Los Angeles Times                 983,727                 653,868   \n",
              "4      Washington Post                 760,034                 474,767   \n",
              "\n",
              "  Change in Daily Circulation, 2004-2013  \\\n",
              "0                                   -24%   \n",
              "1                                   +13%   \n",
              "2                                   +67%   \n",
              "3                                   -34%   \n",
              "4                                   -38%   \n",
              "\n",
              "   Pulitzer Prize Winners and Finalists, 1990-2003  \\\n",
              "0                                                1   \n",
              "1                                               30   \n",
              "2                                               55   \n",
              "3                                               44   \n",
              "4                                               52   \n",
              "\n",
              "   Pulitzer Prize Winners and Finalists, 2004-2014  \\\n",
              "0                                                1   \n",
              "1                                               20   \n",
              "2                                               62   \n",
              "3                                               41   \n",
              "4                                               48   \n",
              "\n",
              "   Pulitzer Prize Winners and Finalists, 1990-2014  \n",
              "0                                                2  \n",
              "1                                               50  \n",
              "2                                              117  \n",
              "3                                               85  \n",
              "4                                              100  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a66e8b1-76c4-4e06-bd4e-374c74c7e38c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Newspaper</th>\n",
              "      <th>Daily Circulation, 2004</th>\n",
              "      <th>Daily Circulation, 2013</th>\n",
              "      <th>Change in Daily Circulation, 2004-2013</th>\n",
              "      <th>Pulitzer Prize Winners and Finalists, 1990-2003</th>\n",
              "      <th>Pulitzer Prize Winners and Finalists, 2004-2014</th>\n",
              "      <th>Pulitzer Prize Winners and Finalists, 1990-2014</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>USA Today</td>\n",
              "      <td>2,192,098</td>\n",
              "      <td>1,674,306</td>\n",
              "      <td>-24%</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wall Street Journal</td>\n",
              "      <td>2,101,017</td>\n",
              "      <td>2,378,827</td>\n",
              "      <td>+13%</td>\n",
              "      <td>30</td>\n",
              "      <td>20</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New York Times</td>\n",
              "      <td>1,119,027</td>\n",
              "      <td>1,865,318</td>\n",
              "      <td>+67%</td>\n",
              "      <td>55</td>\n",
              "      <td>62</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Los Angeles Times</td>\n",
              "      <td>983,727</td>\n",
              "      <td>653,868</td>\n",
              "      <td>-34%</td>\n",
              "      <td>44</td>\n",
              "      <td>41</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Washington Post</td>\n",
              "      <td>760,034</td>\n",
              "      <td>474,767</td>\n",
              "      <td>-38%</td>\n",
              "      <td>52</td>\n",
              "      <td>48</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a66e8b1-76c4-4e06-bd4e-374c74c7e38c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a66e8b1-76c4-4e06-bd4e-374c74c7e38c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a66e8b1-76c4-4e06-bd4e-374c74c7e38c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def VectorizeAndClassify(vectorizers_list, classifiers_list):\n",
        "    for v in vectorizers_list:\n",
        "        for c in classifiers_list:\n",
        "            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n",
        "            score = cross_val_score(pipeline1, data['name'], data['airline_sentiment'], scoring='accuracy', cv=3).mean()\n",
        "            print('Векторизация - {}'.format(v))\n",
        "            print('Модель для классификации - {}'.format(c))\n",
        "            print('Accuracy = {}'.format(score))\n",
        "            print('===========================')"
      ],
      "metadata": {
        "id": "5Nh8L2Ee79Xl"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizers_list = [CountVectorizer(vocabulary = corpusVocab), TfidfVectorizer(vocabulary = corpusVocab)]\n",
        "classifiers_list = [LogisticRegression(C=3.0), MultinomialNB()]\n",
        "VectorizeAndClassify(vectorizers_list, classifiers_list)"
      ],
      "metadata": {
        "id": "XtrCP8eI7-Pq",
        "outputId": "42680afd-f9f4-41f2-e9b3-ab875be6e067",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Векторизация - CountVectorizer(vocabulary={'0504traveller': 0, '09202010': 1,\n",
            "                            '0veranalyser': 2, '0xjared': 3, '10eshaa': 4,\n",
            "                            '1234567890_': 5, '140justinc': 6, '18handicap': 7,\n",
            "                            '1_7_8_0': 8, '1jensaba': 9, '1kingmeech': 10,\n",
            "                            '1lovept': 11, '1malindac': 12,\n",
            "                            '1misterhandsome': 13, '1stcrown': 14,\n",
            "                            '201chef': 15, '215strongbul': 16, '219jondn': 17,\n",
            "                            '21stcenturymom': 18, '2533107724paul': 19,\n",
            "                            '27_powers': 20, '29mc29': 21, '2avsagas': 22,\n",
            "                            '2cjustice4all': 23, '2emmyz': 24, '2hats1mike': 25,\n",
            "                            '2littlebirds': 26, '2lnr': 27, '2tsierole': 28,\n",
            "                            '2v': 29, ...})\n",
            "Модель для классификации - LogisticRegression(C=3.0)\n",
            "Accuracy = 0.6157786885245902\n",
            "===========================\n",
            "Векторизация - CountVectorizer(vocabulary={'0504traveller': 0, '09202010': 1,\n",
            "                            '0veranalyser': 2, '0xjared': 3, '10eshaa': 4,\n",
            "                            '1234567890_': 5, '140justinc': 6, '18handicap': 7,\n",
            "                            '1_7_8_0': 8, '1jensaba': 9, '1kingmeech': 10,\n",
            "                            '1lovept': 11, '1malindac': 12,\n",
            "                            '1misterhandsome': 13, '1stcrown': 14,\n",
            "                            '201chef': 15, '215strongbul': 16, '219jondn': 17,\n",
            "                            '21stcenturymom': 18, '2533107724paul': 19,\n",
            "                            '27_powers': 20, '29mc29': 21, '2avsagas': 22,\n",
            "                            '2cjustice4all': 23, '2emmyz': 24, '2hats1mike': 25,\n",
            "                            '2littlebirds': 26, '2lnr': 27, '2tsierole': 28,\n",
            "                            '2v': 29, ...})\n",
            "Модель для классификации - MultinomialNB()\n",
            "Accuracy = 0.6280054644808742\n",
            "===========================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Векторизация - TfidfVectorizer(vocabulary={'0504traveller': 0, '09202010': 1,\n",
            "                            '0veranalyser': 2, '0xjared': 3, '10eshaa': 4,\n",
            "                            '1234567890_': 5, '140justinc': 6, '18handicap': 7,\n",
            "                            '1_7_8_0': 8, '1jensaba': 9, '1kingmeech': 10,\n",
            "                            '1lovept': 11, '1malindac': 12,\n",
            "                            '1misterhandsome': 13, '1stcrown': 14,\n",
            "                            '201chef': 15, '215strongbul': 16, '219jondn': 17,\n",
            "                            '21stcenturymom': 18, '2533107724paul': 19,\n",
            "                            '27_powers': 20, '29mc29': 21, '2avsagas': 22,\n",
            "                            '2cjustice4all': 23, '2emmyz': 24, '2hats1mike': 25,\n",
            "                            '2littlebirds': 26, '2lnr': 27, '2tsierole': 28,\n",
            "                            '2v': 29, ...})\n",
            "Модель для классификации - LogisticRegression(C=3.0)\n",
            "Accuracy = 0.6157786885245902\n",
            "===========================\n",
            "Векторизация - TfidfVectorizer(vocabulary={'0504traveller': 0, '09202010': 1,\n",
            "                            '0veranalyser': 2, '0xjared': 3, '10eshaa': 4,\n",
            "                            '1234567890_': 5, '140justinc': 6, '18handicap': 7,\n",
            "                            '1_7_8_0': 8, '1jensaba': 9, '1kingmeech': 10,\n",
            "                            '1lovept': 11, '1malindac': 12,\n",
            "                            '1misterhandsome': 13, '1stcrown': 14,\n",
            "                            '201chef': 15, '215strongbul': 16, '219jondn': 17,\n",
            "                            '21stcenturymom': 18, '2533107724paul': 19,\n",
            "                            '27_powers': 20, '29mc29': 21, '2avsagas': 22,\n",
            "                            '2cjustice4all': 23, '2emmyz': 24, '2hats1mike': 25,\n",
            "                            '2littlebirds': 26, '2lnr': 27, '2tsierole': 28,\n",
            "                            '2v': 29, ...})\n",
            "Модель для классификации - MultinomialNB()\n",
            "Accuracy = 0.6280054644808742\n",
            "===========================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Разделим выборку на обучающую и тестовую**"
      ],
      "metadata": {
        "id": "H1qlza1eeet3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data['name'], data['airline_sentiment'], test_size=0.5, random_state=1)\n"
      ],
      "metadata": {
        "id": "56jdCNGh7_4k"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment(v, c):\n",
        "    model = Pipeline(\n",
        "        [(\"vectorizer\", v), \n",
        "         (\"classifier\", c)])\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print_accuracy_score_for_classes(y_test, y_pred)"
      ],
      "metadata": {
        "id": "-pcLJc8DfK9c"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment(TfidfVectorizer(), LogisticRegression(C=5.0))\n"
      ],
      "metadata": {
        "id": "waYilFzrfPvw",
        "outputId": "c15a3f9a-d067-4cb3-cc92-bb7fdd2d4fc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метка \t Accuracy\n",
            "negative \t 0.9344760251681493\n",
            "neutral \t 0.20038659793814434\n",
            "positive \t 0.09577221742881795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment(TfidfVectorizer(ngram_range=(1,3)), LogisticRegression(C=5.0))\n"
      ],
      "metadata": {
        "id": "lxa4iPkJfUO9",
        "outputId": "830a1dd2-b387-4fab-c2ff-e93b2b422c1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метка \t Accuracy\n",
            "negative \t 0.9344760251681493\n",
            "neutral \t 0.20038659793814434\n",
            "positive \t 0.09577221742881795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment(TfidfVectorizer(ngram_range=(2,3)), LogisticRegression(C=5.0))\n"
      ],
      "metadata": {
        "id": "4rlD9jSkfWx-",
        "outputId": "ed269aa5-28cc-457d-f5be-26c6476f6ac0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метка \t Accuracy\n",
            "negative \t 1.0\n",
            "neutral \t 0.0\n",
            "positive \t 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment(TfidfVectorizer(ngram_range=(1,4)), LogisticRegression(C=5.0))\n"
      ],
      "metadata": {
        "id": "Qkifd9o3fkTY",
        "outputId": "fcae2e5f-a592-46f9-896c-4df7b6fc3851",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метка \t Accuracy\n",
            "negative \t 0.9344760251681493\n",
            "neutral \t 0.20038659793814434\n",
            "positive \t 0.09577221742881795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment(TfidfVectorizer(ngram_range=(2,4)), LogisticRegression(C=5.0))\n"
      ],
      "metadata": {
        "id": "VpebntCIfnxT",
        "outputId": "0c8cff72-7567-406a-f5f6-8f2638b8bbdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метка \t Accuracy\n",
            "negative \t 1.0\n",
            "neutral \t 0.0\n",
            "positive \t 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод:**  \n",
        "Как видно из результатов, лучшую точность показал *CountVectorizer* и *MultinomialNB*.  \n",
        "Точность составила 62,8%."
      ],
      "metadata": {
        "id": "tmg8xZRH8D1q"
      }
    }
  ]
}